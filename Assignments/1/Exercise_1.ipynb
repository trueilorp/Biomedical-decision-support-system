{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4cfc527e-72e7-4488-9065-4393eee5f479",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================\n",
      "RUN APRIORI ALGORITHMS\n",
      "======================\n",
      "\n",
      "=== Dataset: data1 ===\n",
      "Standard Apriori:\n",
      "  itemset: {'A1': (1, 4), 'A2': (0, 4)}  support: 1.0\n",
      "  itemset: {'A1': (0, 3), 'A2': (0, 4)}  support: 0.8\n",
      "  itemset: {'A1': (0, 4), 'A2': (1, 4)}  support: 1.0\n",
      "  itemset: {'A1': (0, 4), 'A2': (0, 3)}  support: 0.4\n",
      "  itemset: {'A1': (2, 4), 'A2': (0, 4)}  support: 0.6\n",
      "  itemset: {'A1': (1, 3), 'A2': (0, 4)}  support: 0.8\n",
      "  itemset: {'A1': (1, 4), 'A2': (1, 4)}  support: 1.0\n",
      "  itemset: {'A1': (1, 4), 'A2': (0, 3)}  support: 0.4\n",
      "  itemset: {'A1': (0, 2), 'A2': (0, 4)}  support: 0.4\n",
      "  itemset: {'A1': (0, 3), 'A2': (1, 4)}  support: 0.8\n",
      "  itemset: {'A1': (0, 4), 'A2': (2, 4)}  support: 0.8\n",
      "  itemset: {'A1': (0, 4), 'A2': (1, 3)}  support: 0.4\n",
      "  itemset: {'A1': (2, 3), 'A2': (0, 4)}  support: 0.4\n",
      "  itemset: {'A1': (2, 4), 'A2': (1, 4)}  support: 0.6\n",
      "  itemset: {'A1': (2, 4), 'A2': (0, 3)}  support: 0.4\n",
      "  itemset: {'A1': (1, 2), 'A2': (0, 4)}  support: 0.4\n",
      "  itemset: {'A1': (1, 3), 'A2': (1, 4)}  support: 0.8\n",
      "  itemset: {'A1': (1, 4), 'A2': (2, 4)}  support: 0.8\n",
      "  itemset: {'A1': (1, 4), 'A2': (1, 3)}  support: 0.4\n",
      "  itemset: {'A1': (0, 2), 'A2': (1, 4)}  support: 0.4\n",
      "  itemset: {'A1': (0, 3), 'A2': (2, 4)}  support: 0.8\n",
      "  itemset: {'A1': (0, 4), 'A2': (3, 4)}  support: 0.4\n",
      "  itemset: {'A1': (2, 3), 'A2': (1, 4)}  support: 0.4\n",
      "  itemset: {'A1': (2, 4), 'A2': (2, 4)}  support: 0.4\n",
      "  itemset: {'A1': (2, 4), 'A2': (1, 3)}  support: 0.4\n",
      "  itemset: {'A1': (1, 2), 'A2': (1, 4)}  support: 0.4\n",
      "  itemset: {'A1': (1, 3), 'A2': (2, 4)}  support: 0.8\n",
      "  itemset: {'A1': (1, 4), 'A2': (3, 4)}  support: 0.4\n",
      "  itemset: {'A1': (0, 2), 'A2': (2, 4)}  support: 0.4\n",
      "  itemset: {'A1': (0, 3), 'A2': (3, 4)}  support: 0.4\n",
      "  itemset: {'A1': (2, 3), 'A2': (2, 4)}  support: 0.4\n",
      "  itemset: {'A1': (1, 2), 'A2': (2, 4)}  support: 0.4\n",
      "  itemset: {'A1': (1, 3), 'A2': (3, 4)}  support: 0.4\n",
      "Randomic Apriori:\n",
      "  itemset: {'A1': (0, 4), 'A2': (0, 4)}  support: 1.0\n",
      "\n",
      "=== Dataset: data2 ===\n",
      "Standard Apriori:\n",
      "  itemset: {'A1': (1, 2), 'A2': (0, 2)}  support: 1.0\n",
      "  itemset: {'A1': (0, 2), 'A2': (1, 2)}  support: 0.8\n",
      "  itemset: {'A1': (1, 2), 'A2': (1, 2)}  support: 0.8\n",
      "Randomic Apriori:\n",
      "  itemset: {'A1': (0, 2), 'A2': (0, 2)}  support: 1.0\n",
      "\n",
      "=== Dataset: data3 ===\n",
      "Standard Apriori:\n",
      "  itemset: {'A1': (1, 4), 'A2': (0, 6)}  support: 0.8\n",
      "  itemset: {'A1': (0, 3), 'A2': (0, 6)}  support: 0.8\n",
      "  itemset: {'A1': (0, 4), 'A2': (1, 6)}  support: 0.8\n",
      "  itemset: {'A1': (2, 4), 'A2': (0, 6)}  support: 0.4\n",
      "  itemset: {'A1': (1, 3), 'A2': (0, 6)}  support: 0.8\n",
      "  itemset: {'A1': (1, 4), 'A2': (1, 6)}  support: 0.8\n",
      "  itemset: {'A1': (0, 2), 'A2': (0, 6)}  support: 0.4\n",
      "  itemset: {'A1': (0, 3), 'A2': (1, 6)}  support: 0.8\n",
      "  itemset: {'A1': (0, 4), 'A2': (2, 6)}  support: 0.8\n",
      "  itemset: {'A1': (2, 3), 'A2': (0, 6)}  support: 0.4\n",
      "  itemset: {'A1': (2, 4), 'A2': (1, 6)}  support: 0.4\n",
      "  itemset: {'A1': (1, 2), 'A2': (0, 6)}  support: 0.4\n",
      "  itemset: {'A1': (1, 3), 'A2': (1, 6)}  support: 0.8\n",
      "  itemset: {'A1': (1, 4), 'A2': (2, 6)}  support: 0.8\n",
      "  itemset: {'A1': (0, 2), 'A2': (1, 6)}  support: 0.4\n",
      "  itemset: {'A1': (0, 3), 'A2': (2, 6)}  support: 0.8\n",
      "  itemset: {'A1': (0, 4), 'A2': (3, 6)}  support: 0.8\n",
      "  itemset: {'A1': (2, 3), 'A2': (1, 6)}  support: 0.4\n",
      "  itemset: {'A1': (2, 4), 'A2': (2, 6)}  support: 0.4\n",
      "  itemset: {'A1': (1, 2), 'A2': (1, 6)}  support: 0.4\n",
      "  itemset: {'A1': (1, 3), 'A2': (2, 6)}  support: 0.8\n",
      "  itemset: {'A1': (1, 4), 'A2': (3, 6)}  support: 0.8\n",
      "  itemset: {'A1': (0, 2), 'A2': (2, 6)}  support: 0.4\n",
      "  itemset: {'A1': (0, 3), 'A2': (3, 6)}  support: 0.8\n",
      "  itemset: {'A1': (0, 4), 'A2': (4, 6)}  support: 0.8\n",
      "  itemset: {'A1': (2, 3), 'A2': (2, 6)}  support: 0.4\n",
      "  itemset: {'A1': (2, 4), 'A2': (3, 6)}  support: 0.4\n",
      "  itemset: {'A1': (1, 2), 'A2': (2, 6)}  support: 0.4\n",
      "  itemset: {'A1': (1, 3), 'A2': (3, 6)}  support: 0.8\n",
      "  itemset: {'A1': (1, 4), 'A2': (4, 6)}  support: 0.8\n",
      "  itemset: {'A1': (0, 2), 'A2': (3, 6)}  support: 0.4\n",
      "  itemset: {'A1': (0, 3), 'A2': (4, 6)}  support: 0.8\n",
      "  itemset: {'A1': (0, 4), 'A2': (5, 6)}  support: 0.6\n",
      "  itemset: {'A1': (2, 3), 'A2': (3, 6)}  support: 0.4\n",
      "  itemset: {'A1': (2, 4), 'A2': (4, 6)}  support: 0.4\n",
      "  itemset: {'A1': (1, 2), 'A2': (3, 6)}  support: 0.4\n",
      "  itemset: {'A1': (1, 3), 'A2': (4, 6)}  support: 0.8\n",
      "  itemset: {'A1': (1, 4), 'A2': (5, 6)}  support: 0.6\n",
      "  itemset: {'A1': (0, 2), 'A2': (4, 6)}  support: 0.4\n",
      "  itemset: {'A1': (0, 3), 'A2': (5, 6)}  support: 0.6\n",
      "  itemset: {'A1': (2, 3), 'A2': (4, 6)}  support: 0.4\n",
      "  itemset: {'A1': (2, 4), 'A2': (5, 6)}  support: 0.4\n",
      "  itemset: {'A1': (1, 2), 'A2': (4, 6)}  support: 0.4\n",
      "  itemset: {'A1': (1, 3), 'A2': (5, 6)}  support: 0.6\n",
      "  itemset: {'A1': (2, 3), 'A2': (5, 6)}  support: 0.4\n",
      "Randomic Apriori:\n",
      "  itemset: {'A1': (0, 4), 'A2': (0, 6)}  support: 0.8\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from multiprocessing import Manager, Process\n",
    "from IPython.display import display\n",
    "\n",
    "# ======================\n",
    "# Utility Functions\n",
    "# ======================\n",
    "def point_in_interval(point, interval):\n",
    "\treturn interval[0] < point < interval[1]\n",
    "\n",
    "def satisfies(itemset, row):\n",
    "\treturn all(point_in_interval(row[attr], itemset[attr]) for attr in itemset)\n",
    "\n",
    "def support(itemset, data, class_col):\n",
    "\ttotal_c = data[class_col].sum()\n",
    "\tmatched = data[data.apply(lambda row: satisfies(itemset, row), axis=1)]\n",
    "\treturn matched[class_col].sum() / total_c if total_c > 0 else 0\n",
    "\n",
    "def shrink_difference(inner, outer):\n",
    "\treturn (inner[0] - outer[0]) + (outer[1] - inner[1])\n",
    "\n",
    "def delta(itemset, max_vals):\n",
    "\treturn sum(shrink_difference(itemset[attr], (0, max_vals[attr])) for attr in itemset)\n",
    "\n",
    "# ======================\n",
    "# Standard Apriori\n",
    "# ======================\n",
    "def apriori_standard(data, epsilon, class_col):\n",
    "\tattributes = [col for col in data.columns if col != class_col] # ricavo i nomi delle colonne\n",
    "\tmax_vals = {a: int(np.ceil(data[a].max())) for a in attributes} # ricavo i max val con cui costruire il mio bottom itemset\n",
    "\tI0 = {a: (0, max_vals[a]) for a in attributes} # definisco il bottom itemset\n",
    "\tR, SWk = {}, [I0] # inizializzo R (relations) e SWk (set of supported witnesses)\n",
    "\t\n",
    "\t# print(\"Bottom itemset: \" + str(I0))\n",
    "\t\n",
    "\twhile SWk:\n",
    "\t\tWk = []\n",
    "\t\tfor I in SWk: # esploro tutti gli itemset\n",
    "\t\t\tfor a in attributes:\n",
    "\t\t\t\tb, e = I[a]\n",
    "\t\t\t\t# restringo bordo inferiore di 1 (se possibile)\n",
    "\t\t\t\tif b + 1 < e:\n",
    "\t\t\t\t\tnew_I = I.copy()\n",
    "\t\t\t\t\tnew_I[a] = (b + 1, e)\n",
    "\t\t\t\t\tWk.append(new_I)\n",
    "\n",
    "\t\t\t\t# restringo bordo superiore di 1 (se possibile)\n",
    "\t\t\t\tif b < e - 1:\n",
    "\t\t\t\t\tnew_I = I.copy()\n",
    "\t\t\t\t\tnew_I[a] = (b, e - 1)\n",
    "\t\t\t\t\tWk.append(new_I)\n",
    "\t\tSWk = []\n",
    "\t\tfor I in Wk:\n",
    "\t\t\ts = support(I, data, class_col) # calcolo supporto con la funzione support\n",
    "\t\t\tif s >= epsilon:\n",
    "\t\t\t\tR[str(I)] = s\n",
    "\t\t\t\tSWk.append(I)\n",
    "\treturn R\n",
    "\n",
    "# ======================\n",
    "# Randomic Apriori\n",
    "# ======================\n",
    "def is_predecessor(Ip, I):\n",
    "\tfor a in I:\n",
    "\t\tb1, e1 = Ip[a]\n",
    "\t\tb2, e2 = I[a]\n",
    "\t\tif not (b1 <= b2 and e2 <= e1):\n",
    "\t\t\treturn False\n",
    "\treturn True\n",
    "\n",
    "def is_successor(In, I):\n",
    "\tfor a in I:\n",
    "\t\tb1, e1 = I[a]\n",
    "\t\tb2, e2 = In[a]\n",
    "\t\tif not (b2 <= b1 and e1 <= e2):\n",
    "\t\t\treturn False\n",
    "\treturn True\n",
    "\n",
    "def apriori_randomic(data, epsilon, class_col):\n",
    "\tattributes = [c for c in data.columns if c != class_col]\n",
    "\tmax_vals = {a: int(np.ceil(data[a].max())) for a in attributes}\n",
    "\tI0 = {a: (0, max_vals[a]) for a in attributes}\n",
    "\n",
    "\tR, LP, LS, LNS = {}, [I0], {}, {}\n",
    "\t\t\n",
    "\twhile LP:\n",
    "\t\tI = LP.pop(random.randint(0, len(LP) - 1)) # rimuovo I da LP\n",
    "\t\tkey = tuple((a, I[a]) for a in attributes)  # rappresentazione stabile\n",
    "\n",
    "\t\t# Se esiste un predecessore supportato o un successore non supportato, salto\n",
    "\t\tif any(is_predecessor(eval(k), I) for k in LS.keys()) or \\\n",
    "\t\t   any(is_successor(eval(k), I) for k in LNS.keys()):\n",
    "\t\t\tcontinue\n",
    "\n",
    "\t\t# Calcolo supporto\n",
    "\t\ts = support(I, data, class_col)\n",
    "\n",
    "\t\tif s >= epsilon:\n",
    "\t\t\tR[str(I)] = s\n",
    "\t\t\tLS[str(I)] = s\n",
    "\t\t\t# Generazione figli\n",
    "\t\t\tfor a in attributes:\n",
    "\t\t\t\tb, e = I[a]\n",
    "\t\t\t\t# restringo il bordo inferiore di 1, se possibile\n",
    "\t\t\t\tif b + 1 < e:\n",
    "\t\t\t\t\tnew_I = I.copy()\n",
    "\t\t\t\t\tnew_I[a] = (b + 1, e)\n",
    "\t\t\t\t\tLP.append(new_I)\n",
    "\n",
    "\t\t\t\t# restringo il bordo superiore di 1, se possibile\n",
    "\t\t\t\tif b < e - 1:\n",
    "\t\t\t\t\tnew_I = I.copy()\n",
    "\t\t\t\t\tnew_I[a] = (b, e - 1)\n",
    "\t\t\t\t\tLP.append(new_I)\n",
    "\t\telse:\n",
    "\t\t\tLNS[str(I)] = s\n",
    "\n",
    "\treturn R\n",
    "\n",
    "\n",
    "# ======================\n",
    "# Run All Algorithms\n",
    "# ======================\n",
    "print(\"\\n======================\")\n",
    "print(\"RUN APRIORI ALGORITHMS\")\n",
    "print(\"======================\")\n",
    "\n",
    "data1 = pd.DataFrame({\n",
    "\t'A1': [1.2, 2.5, 3.1, 2.9, 1.5],\n",
    "\t'A2': [3.0, 3.5, 2.0, 2.2, 3.1],\n",
    "\t'C':  [1, 1, 1, 1, 1]\n",
    "})\n",
    "\n",
    "data2 = pd.DataFrame({\n",
    "\t'A1': [1.2, 1.3, 1.1, 1.9, 1.5],\n",
    "\t'A2': [1.6, 1.5, 1.0, 1.2, 1.1],\n",
    "\t'C':  [1, 1, 1, 1, 1]\n",
    "})\n",
    "\n",
    "data3 = pd.DataFrame({\n",
    "\t'A1': [1.2, 2.5, 3.1, 2.9, 1.5], \n",
    "\t'A2': [5.0, 5.5, 6.0, 5.2, 5.1], \n",
    "\t'C': [1, 1, 1, 1, 1]})\n",
    "\n",
    "datasets = {\"data1\": data1, \"data2\": data2, \"data3\": data3}\n",
    "epsilon = 0.4\n",
    "\n",
    "# ======================\n",
    "# Print Results\n",
    "# ======================\n",
    "\n",
    "for name, data in datasets.items():\n",
    "\tstd_result = apriori_standard(data, epsilon, 'C')\n",
    "\trnd_result = apriori_randomic(data, epsilon, 'C')\n",
    "\n",
    "\tprint(\"\\n=== Dataset:\", name, \"===\")\n",
    "\n",
    "\tprint(\"Standard Apriori:\")\n",
    "\tfor k, v in std_result.items():\n",
    "\t\tprint(\"  itemset:\", k, \" support:\", v)\n",
    "\n",
    "\tprint(\"Randomic Apriori:\")\n",
    "\tfor k, v in rnd_result.items():\n",
    "\t\tprint(\"  itemset:\", k, \" support:\", v)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
