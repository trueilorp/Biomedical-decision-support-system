{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f5e80b65",
   "metadata": {},
   "source": [
    "## **Extract all the association rules with confidence greater than or equal to 0.8 involving just itemsets in the frontier**\n",
    "For each rule:\n",
    "- Measure the p-value\n",
    "- Calculate the lift\n",
    "- Visualize the rules in a re-translated fashion\n",
    "to gain insights on the real values of the attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a25da0e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start extracting association rules...\n",
      "\n",
      "------------------------------\n",
      "\n",
      "Generated Rules:\n",
      "{'A1': (0, 3)} -> {'A2': (0, 6)}\n",
      "{'A2': (0, 6)} -> {'A1': (0, 3)}\n",
      "{'A1': (0, 2)} -> {'A2': (0, 6)}\n",
      "{'A2': (0, 6)} -> {'A1': (0, 2)}\n",
      "{'A1': (0, 4)} -> {'A2': (0, 6)}\n",
      "{'A2': (0, 6)} -> {'A1': (0, 4)}\n",
      "\n",
      "Final Association Rules:\n",
      "{'antecedent': {'A1': (0, 3)}, 'consequent': {'A2': (0, 6)}, 'support': 0.8, 'confidence': 1.0, 'lift': 1.25, 'p_value': 0.2}\n",
      "{'antecedent': {'A2': (0, 6)}, 'consequent': {'A1': (0, 3)}, 'support': 0.8, 'confidence': 1.0, 'lift': 1.25, 'p_value': 0.2}\n",
      "{'antecedent': {'A1': (0, 2)}, 'consequent': {'A2': (0, 6)}, 'support': 0.4, 'confidence': 1.0, 'lift': 1.25, 'p_value': 0.6}\n",
      "{'antecedent': {'A1': (0, 4)}, 'consequent': {'A2': (0, 6)}, 'support': 0.8, 'confidence': 0.8, 'lift': 1.0, 'p_value': 1.0}\n",
      "{'antecedent': {'A2': (0, 6)}, 'consequent': {'A1': (0, 4)}, 'support': 0.8, 'confidence': 1.0, 'lift': 1.0, 'p_value': 1.0}\n",
      "\n",
      "Formatted Rules:\n",
      "IF A1 in [0, 3] THEN A2 in [0, 6] | Support: 0.800, Confidence: 1.000, Lift: 1.250, p-value: 0.2\n",
      "IF A2 in [0, 6] THEN A1 in [0, 3] | Support: 0.800, Confidence: 1.000, Lift: 1.250, p-value: 0.2\n",
      "IF A1 in [0, 2] THEN A2 in [0, 6] | Support: 0.400, Confidence: 1.000, Lift: 1.250, p-value: 0.6\n",
      "IF A1 in [0, 4] THEN A2 in [0, 6] | Support: 0.800, Confidence: 0.800, Lift: 1.000, p-value: 1.0\n",
      "IF A2 in [0, 6] THEN A1 in [0, 4] | Support: 0.800, Confidence: 1.000, Lift: 1.000, p-value: 1.0\n"
     ]
    }
   ],
   "source": [
    "# input \n",
    "import itertools\n",
    "def get_rules_from_itemset(freq_i):\n",
    "\tall_rules = []\n",
    "\tfor itemset in freq_i:\n",
    "\t\tkeys = list(itemset.keys())\n",
    "\t\tk = len(keys)\n",
    "\n",
    "\t\t# tutte le possibili combinazioni con itertools.combinations non vuote e non complete\n",
    "\t\tfor r in range(1, k):\n",
    "\t\t\tfor lhs_keys in itertools.combinations(keys, r):\n",
    "\t\t\t\tlhs_dict = {k: itemset[k] for k in lhs_keys}\n",
    "\t\t\t\trhs_keys = set(keys) - set(lhs_keys)\n",
    "\t\t\t\trhs_dict = {k: itemset[k] for k in rhs_keys}\n",
    "\t\t\t\tall_rules.append((lhs_dict, rhs_dict))\n",
    "\treturn all_rules\n",
    "\n",
    "def calc_support(df, itemset, weight_col):\n",
    "\t\"\"\"\n",
    "\titemset è un dict: {colonna: (min_val, max_val), ...}\n",
    "\t\"\"\"\n",
    "\ttotal_weight = df[weight_col].sum()  # somma di tutti i pesi\n",
    "\tnum_sum = 0\n",
    "\n",
    "\t# iteriamo sulle righe del dataframe\n",
    "\tfor index, row in df.iterrows():\n",
    "\t\tmatch = True  # assumiamo che la riga soddisfi le condizioni\n",
    "\n",
    "\t\tfor col, (low, high) in itemset.items():\n",
    "\t\t\tvalue = row[col]\n",
    "\n",
    "\t\t\t# controllo se il valore è dentro i bounds\n",
    "\t\t\tif not (low <= value < high):\n",
    "\t\t\t\tmatch = False\n",
    "\t\t\t\tbreak\n",
    "\n",
    "\t\t# se la riga soddisfa tutti i vincoli dell'itemset\n",
    "\t\tif match:\n",
    "\t\t\tnum_sum += row[weight_col]\n",
    "\n",
    "\tsupport = num_sum / total_weight if total_weight > 0 else 0\n",
    "\treturn support\n",
    "\n",
    "def print_rules(all_rules):\n",
    "\tprint(\"Generated Rules:\")\n",
    "\tfor rule in all_rules:\n",
    "\t\tprint(rule[0], \"->\", rule[1])\n",
    "\n",
    "def extract_association_rules(df, frequent_itemset, min_confidence, weight_col='weight'):\n",
    "\tall_rules = get_rules_from_itemset(frequent_itemset)\n",
    "\tfinal_association_rules = []\n",
    "\tprint_rules(all_rules)\n",
    "\n",
    "\tfor rule in all_rules:\n",
    "\t\titemset = {**rule[0], **rule[1]} # estraggo antecedente e consequente e creo l'itemset\n",
    "\t\t# print(\"Itemset: \" + str(itemset))\n",
    "\t\t\n",
    "\t\tsupport = calc_support(df, itemset, weight_col) # calcolo il supporto dell'itemset\n",
    "\t\t# print(\"Support: \" + str(support))\n",
    "\t\t\n",
    "\t\t# calcolo la confidence\n",
    "\t\tsupport_antecedent = calc_support(df, rule[0], weight_col)\n",
    "\t\t# print(\"Antecedent: \" + str(rule[0]))\n",
    "\t\t# print(\"Support Antecedent: \" + str(support_antecedent))\t\n",
    "\t\t\n",
    "\t\tif support_antecedent == 0:\n",
    "\t\t\tconfidence = 0\n",
    "\t\t\tfinal_association_rules.append({\n",
    "\t\t\t\t'antecedent': rule[0],\n",
    "\t\t\t\t'consequent': rule[1],\n",
    "\t\t\t\t'support': support,\n",
    "\t\t\t\t'confidence': confidence\n",
    "\t\t\t})\n",
    "\t\telse:\n",
    "\t\t\tconfidence = support / support_antecedent # formula confidence\n",
    "\t\t\t# print(\"Confidence: \" + str(confidence))\n",
    "\t\t\t\n",
    "\t\t\tif confidence >= min_confidence: # se è maggiore del threshold finisce nelle regole finali\n",
    "\t\t\t\tfinal_association_rules.append({\n",
    "\t\t\t\t\t'antecedent': rule[0],\n",
    "\t\t\t\t\t'consequent': rule[1],\n",
    "\t\t\t\t\t'support': support,\n",
    "\t\t\t\t\t'confidence': confidence\n",
    "\t\t\t\t})\n",
    "\t\t\t\t\n",
    "\treturn final_association_rules\n",
    "\n",
    "def calculate_lift(df, association_rules, weight_col): # indica quanto la presenza di un antecedente aumenta (o diminuisce) la probabilità del conseguente,\n",
    "\tfor rule in association_rules:\n",
    "\t\tconfidence = rule['confidence']\n",
    "\t\tsupport_consequent = calc_support(df, rule['consequent'], weight_col=weight_col)\n",
    "\t\t\n",
    "\t\tlift = confidence / support_consequent if support_consequent > 0 else 0\n",
    "\t\trule['lift'] = lift\n",
    "\treturn association_rules\n",
    "\n",
    "from scipy.stats import fisher_exact\n",
    "def control_sat(itemset, row) -> bool:  # return a boolean\n",
    "\tfor attr in itemset:\n",
    "\t\tif not (itemset[attr][0] < row[attr] < itemset[attr][1]):\n",
    "\t\t\treturn False\n",
    "\treturn True\n",
    "\t\n",
    "def calculate_p_value(df, association_rules, weight_col): # prob di osservare un co-occorenza se x e y sono correlati \n",
    "\t\t\n",
    "\tfor rule in association_rules:\n",
    "\t\t# controllo se row soddisfa tutte le condizioni dell’itemset\n",
    "\t\t# quindi memorizzo in A e B le tracce che soddisfano antecedent e consequent della regola di associazione\n",
    "\t\tA = df.apply(lambda row: control_sat(rule['antecedent'], row), axis=1)\n",
    "\t\tB = df.apply(lambda row: control_sat(rule['consequent'], row), axis=1)\n",
    "\t\t\n",
    "\t\ta = sum(A & B)   # righe che soddisfano sia antecedent che consequent\n",
    "\t\tb = sum(A & ~B)  # righe che soddisfano antecedent ma NON consequent\n",
    "\t\tc = sum(~A & B)  # righe che NON soddisfano antecedent ma soddisfano consequent\n",
    "\t\td = sum(~A & ~B) # righe che non soddisfano né antecedent né consequent\n",
    "\t\t\n",
    "\t\t# creo la tabella di contingenza\n",
    "\t\tcontingency = [[a, b], [c, d]]\n",
    "\t\t\n",
    "\t\t# calcolo il p-value usando il test di Fisher\n",
    "\t\ttry:\n",
    "\t\t\t_, p = fisher_exact(contingency, alternative='greater')\n",
    "\t\texcept:\n",
    "\t\t\tp = 1.0\n",
    "\t\t\t\n",
    "\t\trule['p_value'] = round(p, 3)\n",
    "\treturn association_rules\n",
    "\n",
    "# re-translate association rules\n",
    "def format_itemset(itemset):\n",
    "\tparts = []\n",
    "\tfor attr, (lo, hi) in itemset.items():\n",
    "\t\tparts.append(f\"{attr} in [{lo}, {hi}]\")\n",
    "\treturn \" AND \".join(parts)\n",
    "\n",
    "def format_rule(rule):\n",
    "\tlhs, rhs = rule\n",
    "\tlhs_str = format_itemset(lhs)\n",
    "\trhs_str = format_itemset(rhs)\n",
    "\treturn f\"IF {lhs_str} THEN {rhs_str}\"\n",
    "\n",
    "\n",
    "# ------------ #\n",
    "\n",
    "\n",
    "# test create_association_rules\n",
    "import pandas as pd\n",
    "\n",
    "def main():\n",
    "\tprint(\"\\n------------------------------\\n\")\n",
    "\tdata = pd.DataFrame({\n",
    "\t\t'A1': [1.2, 2.5, 3.1, 2.9, 1.5],\n",
    "\t\t'A2': [5.0, 5.5, 6.0, 5.2, 5.1],\n",
    "\t\t'C': [1, 1, 1, 1, 1]\n",
    "\t})\n",
    "\tdf = pd.DataFrame(data)\n",
    "\n",
    "\t# Frequent itemset di test (dict senza chiavi duplicate e coerenti con il df)\n",
    "\tfrequent_itemset = [\n",
    "\t\t{'A1': (0, 3), 'A2': (0, 6)},\n",
    "\t\t{'A1': (0, 2), 'A2': (0, 6)},\n",
    "\t\t{'A1': (0, 4), 'A2': (0, 6)}\n",
    "\t]\n",
    "\n",
    "\t\n",
    "\t# extract association rules\n",
    "\tweight_col = 'C'\n",
    "\tassociation_rules = extract_association_rules(df, frequent_itemset, min_confidence=0.8, weight_col=weight_col)\n",
    "\t\n",
    "\t# calculate lift for each rule\n",
    "\tassociation_rules = calculate_lift(df, association_rules, weight_col=weight_col)\n",
    "\t\n",
    "\t# calculate p-value for each rule \n",
    "\tassociation_rules = calculate_p_value(df, association_rules, weight_col=weight_col) # più è piccolo più x e y sono correlate\n",
    "\t\n",
    "\tprint(\"\\nFinal Association Rules:\")\n",
    "\tfor rule in association_rules:\n",
    "\t\tprint(rule)\n",
    "\t\t\n",
    "\tprint(\"\\nFormatted Rules:\")\n",
    "\tfor rule in association_rules:\n",
    "\t\tformatted_rule = format_rule((rule['antecedent'], rule['consequent']))\n",
    "\t\tprint(f\"{formatted_rule} | Support: {rule['support']:.3f}, Confidence: {rule['confidence']:.3f}, Lift: {rule['lift']:.3f}, p-value: {rule['p_value']}\")\n",
    "\t\n",
    "print(\"Start extracting association rules...\")\n",
    "main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
