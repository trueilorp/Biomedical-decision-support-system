{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0911360e",
   "metadata": {},
   "source": [
    "## **Assignment - Algorithm Implementation and Testing**\n",
    "- Implement the Apriori, Randomic Apriori, and Randomic Distributed Apriori algorithms for quantitative itemsets in your programming language of choice.\n",
    "- Create a set of test cases to verify the correctness of your implementation.\n",
    "- Ensure your implementation can handle various input sizes and support thresholds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cc99b341",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "daeccf26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define inputs\n",
    "# df = pd.read_csv(\n",
    "#     \"AirQualityUCI.csv\",\n",
    "#     sep=\";\",\n",
    "#     decimal=\",\"\n",
    "# )\n",
    "\n",
    "df = pd.DataFrame({'A1': [1.2, 2.5, 3.1, 2.9, 1.5], 'A2': [5.0, 5.5, 6.0, 5.2, 5.1], 'weight': [1, 1, 1, 1, 1]})\n",
    "\n",
    "epsilon = 0.4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a03f6830",
   "metadata": {},
   "source": [
    "##### **Study of dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0fece8f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5, 3)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f613f310",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 5 entries, 0 to 4\n",
      "Data columns (total 3 columns):\n",
      " #   Column  Non-Null Count  Dtype  \n",
      "---  ------  --------------  -----  \n",
      " 0   A1      5 non-null      float64\n",
      " 1   A2      5 non-null      float64\n",
      " 2   weight  5 non-null      int64  \n",
      "dtypes: float64(2), int64(1)\n",
      "memory usage: 248.0 bytes\n"
     ]
    }
   ],
   "source": [
    "df.head(5)\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cb2d6f56",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reduce dataframe size for test\n",
    "df = df.head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "125cf75c",
   "metadata": {},
   "source": [
    "##### Need to encode *Date* and *Time*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "13a7b3b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # --- Conversione robusta della colonna Date ---\n",
    "# df['Date'] = pd.to_datetime(df['Date'], format='%d/%m/%Y', errors='coerce')\n",
    "\n",
    "# # --- Conversione robusta della colonna Time ---\n",
    "# df['Time'] = pd.to_datetime(df['Time'], format='%H.%M.%S', errors='coerce').dt.time\n",
    "# # A questo punto Time è un oggetto datetime.time, convertiamolo in timedelta\n",
    "# df['Time'] = pd.to_timedelta(df['Time'].astype(str))\n",
    "\n",
    "# df['year'] = df['Date'].dt.year\n",
    "# df['month'] = df['Date'].dt.month\n",
    "# df['day'] = df['Date'].dt.day\n",
    "# df['hour'] = df['Time'].dt.seconds // 3600\n",
    "# df['minute'] = (df['Time'].dt.seconds % 3600) // 60\n",
    "\n",
    "# df.drop(columns=['Date', 'Time'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ea3e5cb5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A1</th>\n",
       "      <th>A2</th>\n",
       "      <th>weight</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.2</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.5</td>\n",
       "      <td>5.5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.1</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.9</td>\n",
       "      <td>5.2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.5</td>\n",
       "      <td>5.1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    A1   A2  weight\n",
       "0  1.2  5.0       1\n",
       "1  2.5  5.5       1\n",
       "2  3.1  6.0       1\n",
       "3  2.9  5.2       1\n",
       "4  1.5  5.1       1"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "563c4cec",
   "metadata": {},
   "source": [
    "##### Create weight column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f9a2ad7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df['weight'] = (df['CO(GT)'] - df['CO(GT)'].min()) / (df['CO(GT)'].max() - df['CO(GT)'].min()) # per ogni riga, creo la colonna 'weight' che normalizza il valore di CO(GT) tra 0 e 1\n",
    "# df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "11249538",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Define utilities\n",
    "def bottom_itemset(dataframe, weught_col):\n",
    "\tbottom_its = {}\n",
    "\tlower_bound = 0\n",
    "\t\n",
    "\tfor column in dataframe.columns:\n",
    "\t\tif (weught_col != column):\n",
    "\t\t\tmax_val = int(np.ceil(dataframe[column].max()))\n",
    "\t\t\tbottom_its[column] = (lower_bound, max_val)\n",
    "\t\n",
    "\treturn bottom_its\n",
    "\n",
    "\n",
    "def calc_support(df, itemset, weight_col):\n",
    "\t\"\"\"\n",
    "\titemset è un dict: {colonna: (min_val, max_val), ...}\n",
    "\t\"\"\"\n",
    "\ttotal_weight = df[weight_col].sum()  # somma di tutti i pesi\n",
    "\tnum_sum = 0\n",
    "\n",
    "\t# iteriamo sulle righe del dataframe\n",
    "\tfor index, row in df.iterrows():\n",
    "\t\tmatch = True  # assumiamo che la riga soddisfi le condizioni\n",
    "\n",
    "\t\tfor col, (low, high) in itemset.items():\n",
    "\t\t\tvalue = row[col]\n",
    "\n",
    "\t\t\t# controllo se il valore è dentro i bounds\n",
    "\t\t\tif not (low <= value < high):\n",
    "\t\t\t\tmatch = False\n",
    "\t\t\t\tbreak\n",
    "\n",
    "\t\t# se la riga soddisfa tutti i vincoli dell'itemset\n",
    "\t\tif match:\n",
    "\t\t\tnum_sum += row[weight_col]\n",
    "\n",
    "\tsupport = num_sum / total_weight if total_weight > 0 else 0\n",
    "\treturn support\n",
    "\n",
    "def calc_shrink_difference(item):\n",
    "\t\"\"\"\n",
    "\titem è un dict: {colonna: (min_val, max_val)}\n",
    "\t\"\"\"\n",
    "\tfor col, (min_val, max_val) in item.items():\n",
    "\t\treturn max_val - min_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "023789ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Base itemset (I0): {'A1': (0, 4), 'A2': (0, 6)}\n",
      "Initial candidate itemsets (s_w): [{'A1': (0, 4)}, {'A2': (0, 6)}]\n",
      "Generating candidates from itemset: {'A1': (0, 4)}\n",
      "  Evaluating candidate: {'A1': (1, 4)}\n",
      "    Shrink difference itemset: 4, Shrink difference candidate: 3\n",
      "    --> {'A1': (1, 4)} added to w_k\n",
      "  Evaluating candidate: {'A1': (0, 3)}\n",
      "    Shrink difference itemset: 4, Shrink difference candidate: 3\n",
      "    --> {'A1': (0, 3)} added to w_k\n",
      "  Evaluating candidate: {'A1': (2, 4)}\n",
      "    Shrink difference itemset: 4, Shrink difference candidate: 2\n",
      "    --> {'A1': (2, 4)} NOT added to w_k\n",
      "  Evaluating candidate: {'A1': (0, 2)}\n",
      "    Shrink difference itemset: 4, Shrink difference candidate: 2\n",
      "    --> {'A1': (0, 2)} NOT added to w_k\n",
      "  Evaluating candidate: {'A1': (3, 4)}\n",
      "    Shrink difference itemset: 4, Shrink difference candidate: 1\n",
      "    --> {'A1': (3, 4)} NOT added to w_k\n",
      "  Evaluating candidate: {'A1': (0, 1)}\n",
      "    Shrink difference itemset: 4, Shrink difference candidate: 1\n",
      "    --> {'A1': (0, 1)} NOT added to w_k\n",
      "Generating candidates from itemset: {'A2': (0, 6)}\n",
      "  Evaluating candidate: {'A2': (1, 6)}\n",
      "    Shrink difference itemset: 6, Shrink difference candidate: 5\n",
      "    --> {'A2': (1, 6)} added to w_k\n",
      "  Evaluating candidate: {'A2': (0, 5)}\n",
      "    Shrink difference itemset: 6, Shrink difference candidate: 5\n",
      "    --> {'A2': (0, 5)} added to w_k\n",
      "  Evaluating candidate: {'A2': (2, 6)}\n",
      "    Shrink difference itemset: 6, Shrink difference candidate: 4\n",
      "    --> {'A2': (2, 6)} NOT added to w_k\n",
      "  Evaluating candidate: {'A2': (0, 4)}\n",
      "    Shrink difference itemset: 6, Shrink difference candidate: 4\n",
      "    --> {'A2': (0, 4)} NOT added to w_k\n",
      "  Evaluating candidate: {'A2': (3, 6)}\n",
      "    Shrink difference itemset: 6, Shrink difference candidate: 3\n",
      "    --> {'A2': (3, 6)} NOT added to w_k\n",
      "  Evaluating candidate: {'A2': (0, 3)}\n",
      "    Shrink difference itemset: 6, Shrink difference candidate: 3\n",
      "    --> {'A2': (0, 3)} NOT added to w_k\n",
      "  Evaluating candidate: {'A2': (4, 6)}\n",
      "    Shrink difference itemset: 6, Shrink difference candidate: 2\n",
      "    --> {'A2': (4, 6)} NOT added to w_k\n",
      "  Evaluating candidate: {'A2': (0, 2)}\n",
      "    Shrink difference itemset: 6, Shrink difference candidate: 2\n",
      "    --> {'A2': (0, 2)} NOT added to w_k\n",
      "  Evaluating candidate: {'A2': (5, 6)}\n",
      "    Shrink difference itemset: 6, Shrink difference candidate: 1\n",
      "    --> {'A2': (5, 6)} NOT added to w_k\n",
      "  Evaluating candidate: {'A2': (0, 1)}\n",
      "    Shrink difference itemset: 6, Shrink difference candidate: 1\n",
      "    --> {'A2': (0, 1)} NOT added to w_k\n",
      "Evaluating candidates...\n",
      "Itemsets to evaluate: [{'A1': (1, 4)}, {'A1': (0, 3)}, {'A2': (1, 6)}, {'A2': (0, 5)}]\n",
      "Generating candidates from itemset: {'A1': (1, 4)}\n",
      "  Evaluating candidate: {'A1': (2, 4)}\n",
      "    Shrink difference itemset: 3, Shrink difference candidate: 2\n",
      "    --> {'A1': (2, 4)} added to w_k\n",
      "  Evaluating candidate: {'A1': (1, 2)}\n",
      "    Shrink difference itemset: 3, Shrink difference candidate: 1\n",
      "    --> {'A1': (1, 2)} NOT added to w_k\n",
      "  Evaluating candidate: {'A1': (3, 4)}\n",
      "    Shrink difference itemset: 3, Shrink difference candidate: 1\n",
      "    --> {'A1': (3, 4)} NOT added to w_k\n",
      "  Evaluating candidate: {'A1': (1, 1)}\n",
      "    Shrink difference itemset: 3, Shrink difference candidate: 0\n",
      "    --> {'A1': (1, 1)} NOT added to w_k\n",
      "Generating candidates from itemset: {'A1': (0, 3)}\n",
      "  Evaluating candidate: {'A1': (1, 3)}\n",
      "    Shrink difference itemset: 3, Shrink difference candidate: 2\n",
      "    --> {'A1': (1, 3)} added to w_k\n",
      "  Evaluating candidate: {'A1': (0, 2)}\n",
      "    Shrink difference itemset: 3, Shrink difference candidate: 2\n",
      "    --> {'A1': (0, 2)} added to w_k\n",
      "  Evaluating candidate: {'A1': (2, 3)}\n",
      "    Shrink difference itemset: 3, Shrink difference candidate: 1\n",
      "    --> {'A1': (2, 3)} NOT added to w_k\n",
      "  Evaluating candidate: {'A1': (0, 1)}\n",
      "    Shrink difference itemset: 3, Shrink difference candidate: 1\n",
      "    --> {'A1': (0, 1)} NOT added to w_k\n",
      "Generating candidates from itemset: {'A2': (1, 6)}\n",
      "  Evaluating candidate: {'A2': (2, 6)}\n",
      "    Shrink difference itemset: 5, Shrink difference candidate: 4\n",
      "    --> {'A2': (2, 6)} added to w_k\n",
      "  Evaluating candidate: {'A2': (1, 4)}\n",
      "    Shrink difference itemset: 5, Shrink difference candidate: 3\n",
      "    --> {'A2': (1, 4)} NOT added to w_k\n",
      "  Evaluating candidate: {'A2': (3, 6)}\n",
      "    Shrink difference itemset: 5, Shrink difference candidate: 3\n",
      "    --> {'A2': (3, 6)} NOT added to w_k\n",
      "  Evaluating candidate: {'A2': (1, 3)}\n",
      "    Shrink difference itemset: 5, Shrink difference candidate: 2\n",
      "    --> {'A2': (1, 3)} NOT added to w_k\n",
      "  Evaluating candidate: {'A2': (4, 6)}\n",
      "    Shrink difference itemset: 5, Shrink difference candidate: 2\n",
      "    --> {'A2': (4, 6)} NOT added to w_k\n",
      "  Evaluating candidate: {'A2': (1, 2)}\n",
      "    Shrink difference itemset: 5, Shrink difference candidate: 1\n",
      "    --> {'A2': (1, 2)} NOT added to w_k\n",
      "  Evaluating candidate: {'A2': (5, 6)}\n",
      "    Shrink difference itemset: 5, Shrink difference candidate: 1\n",
      "    --> {'A2': (5, 6)} NOT added to w_k\n",
      "  Evaluating candidate: {'A2': (1, 1)}\n",
      "    Shrink difference itemset: 5, Shrink difference candidate: 0\n",
      "    --> {'A2': (1, 1)} NOT added to w_k\n",
      "Evaluating candidates...\n",
      "Itemsets to evaluate: [{'A1': (2, 4)}, {'A1': (1, 3)}, {'A1': (0, 2)}, {'A2': (2, 6)}]\n",
      "Generating candidates from itemset: {'A1': (2, 4)}\n",
      "  Evaluating candidate: {'A1': (3, 4)}\n",
      "    Shrink difference itemset: 2, Shrink difference candidate: 1\n",
      "    --> {'A1': (3, 4)} added to w_k\n",
      "  Evaluating candidate: {'A1': (2, 1)}\n",
      "    Shrink difference itemset: 2, Shrink difference candidate: -1\n",
      "    --> {'A1': (2, 1)} NOT added to w_k\n",
      "Generating candidates from itemset: {'A1': (1, 3)}\n",
      "  Evaluating candidate: {'A1': (2, 3)}\n",
      "    Shrink difference itemset: 2, Shrink difference candidate: 1\n",
      "    --> {'A1': (2, 3)} added to w_k\n",
      "  Evaluating candidate: {'A1': (1, 1)}\n",
      "    Shrink difference itemset: 2, Shrink difference candidate: 0\n",
      "    --> {'A1': (1, 1)} NOT added to w_k\n",
      "Generating candidates from itemset: {'A1': (0, 2)}\n",
      "  Evaluating candidate: {'A1': (1, 2)}\n",
      "    Shrink difference itemset: 2, Shrink difference candidate: 1\n",
      "    --> {'A1': (1, 2)} added to w_k\n",
      "  Evaluating candidate: {'A1': (0, 1)}\n",
      "    Shrink difference itemset: 2, Shrink difference candidate: 1\n",
      "    --> {'A1': (0, 1)} added to w_k\n",
      "Generating candidates from itemset: {'A2': (2, 6)}\n",
      "  Evaluating candidate: {'A2': (3, 6)}\n",
      "    Shrink difference itemset: 4, Shrink difference candidate: 3\n",
      "    --> {'A2': (3, 6)} added to w_k\n",
      "  Evaluating candidate: {'A2': (2, 3)}\n",
      "    Shrink difference itemset: 4, Shrink difference candidate: 1\n",
      "    --> {'A2': (2, 3)} NOT added to w_k\n",
      "  Evaluating candidate: {'A2': (4, 6)}\n",
      "    Shrink difference itemset: 4, Shrink difference candidate: 2\n",
      "    --> {'A2': (4, 6)} NOT added to w_k\n",
      "  Evaluating candidate: {'A2': (2, 2)}\n",
      "    Shrink difference itemset: 4, Shrink difference candidate: 0\n",
      "    --> {'A2': (2, 2)} NOT added to w_k\n",
      "  Evaluating candidate: {'A2': (5, 6)}\n",
      "    Shrink difference itemset: 4, Shrink difference candidate: 1\n",
      "    --> {'A2': (5, 6)} NOT added to w_k\n",
      "  Evaluating candidate: {'A2': (2, 1)}\n",
      "    Shrink difference itemset: 4, Shrink difference candidate: -1\n",
      "    --> {'A2': (2, 1)} NOT added to w_k\n",
      "Evaluating candidates...\n",
      "Itemsets to evaluate: [{'A1': (3, 4)}, {'A1': (2, 3)}, {'A1': (1, 2)}, {'A1': (0, 1)}, {'A2': (3, 6)}]\n",
      "Generating candidates from itemset: {'A1': (2, 3)}\n",
      "Generating candidates from itemset: {'A1': (1, 2)}\n",
      "Generating candidates from itemset: {'A2': (3, 6)}\n",
      "  Evaluating candidate: {'A2': (4, 6)}\n",
      "    Shrink difference itemset: 3, Shrink difference candidate: 2\n",
      "    --> {'A2': (4, 6)} added to w_k\n",
      "  Evaluating candidate: {'A2': (3, 2)}\n",
      "    Shrink difference itemset: 3, Shrink difference candidate: -1\n",
      "    --> {'A2': (3, 2)} NOT added to w_k\n",
      "  Evaluating candidate: {'A2': (5, 6)}\n",
      "    Shrink difference itemset: 3, Shrink difference candidate: 1\n",
      "    --> {'A2': (5, 6)} NOT added to w_k\n",
      "  Evaluating candidate: {'A2': (3, 1)}\n",
      "    Shrink difference itemset: 3, Shrink difference candidate: -2\n",
      "    --> {'A2': (3, 1)} NOT added to w_k\n",
      "Evaluating candidates...\n",
      "Itemsets to evaluate: [{'A2': (4, 6)}]\n",
      "Generating candidates from itemset: {'A2': (4, 6)}\n",
      "  Evaluating candidate: {'A2': (5, 6)}\n",
      "    Shrink difference itemset: 2, Shrink difference candidate: 1\n",
      "    --> {'A2': (5, 6)} added to w_k\n",
      "  Evaluating candidate: {'A2': (4, 1)}\n",
      "    Shrink difference itemset: 2, Shrink difference candidate: -3\n",
      "    --> {'A2': (4, 1)} NOT added to w_k\n",
      "Evaluating candidates...\n",
      "Itemsets to evaluate: [{'A2': (5, 6)}]\n",
      "Generating candidates from itemset: {'A2': (5, 6)}\n",
      "Evaluating candidates...\n",
      "Itemsets to evaluate: []\n",
      "\n",
      "--- Frequent itemsets found: ---\n",
      "\n",
      "Itemset: {'A1': (1, 4)}, Support: 1.0\n",
      "Itemset: {'A1': (0, 3)}, Support: 0.8\n",
      "Itemset: {'A2': (1, 6)}, Support: 0.8\n",
      "Itemset: {'A1': (2, 4)}, Support: 0.6\n",
      "Itemset: {'A1': (1, 3)}, Support: 0.8\n",
      "Itemset: {'A1': (0, 2)}, Support: 0.4\n",
      "Itemset: {'A2': (2, 6)}, Support: 0.8\n",
      "Itemset: {'A1': (2, 3)}, Support: 0.4\n",
      "Itemset: {'A1': (1, 2)}, Support: 0.4\n",
      "Itemset: {'A2': (3, 6)}, Support: 0.8\n",
      "Itemset: {'A2': (4, 6)}, Support: 0.8\n",
      "Itemset: {'A2': (5, 6)}, Support: 0.8\n"
     ]
    }
   ],
   "source": [
    "def a_priori_quant_itemsets(df, epsilon, weight_col='weight'):\n",
    "\trelations = []\n",
    "\tbase = bottom_itemset(df, weight_col) # bottom_itemset restituisce un dict: {col: (low, high)}\n",
    "\tprint(f\"Base itemset (I0): {base}\")\n",
    "\t# s_w parte come lista di itemset a 1 colonna\n",
    "\ts_w = [{col: bounds} for col, bounds in base.items()]\n",
    "\tprint(f\"Initial candidate itemsets (s_w): {s_w}\")\n",
    "\t\n",
    "\tk = 1\n",
    "\twhile s_w:  # finché ho candidati\n",
    "\t\t#print(f\"\\n--- Iterations k={k}, numbers of candidates: {len(s_w)} ---\")\n",
    "\t\tw_k = []\n",
    "\t\t\n",
    "\t\t# genera i candidati\n",
    "\t\tfor item in s_w:\n",
    "\t\t\tprint(f\"Generating candidates from itemset: {item}\")\n",
    "\t\t\tfor col, (low, high) in item.items():\n",
    "\t\t\t\t# print(f\"  Processing column: {col}, bounds: ({low}, {high})\")\n",
    "\t\t\t\tfor mid in range(low + 1, high):\n",
    "\t\t\t\t\tcand1 = {col: (mid, high)}\n",
    "\t\t\t\t\tcand2 = {col: (low, high - mid)}\n",
    "\t\t\t\t\t# print(f\"  Candidate 1: {cand1}, Candidate 2: {cand2}\")\n",
    "\t\t\t\t\t\n",
    "\t\t\t\t\t# i candidati vengono aggiunti a w_k solo se vale l'uguaglianza della shrink difference\n",
    "\t\t\t\t\tcandidates = [cand1, cand2]\n",
    "\t\t\t\t\tshink_difference_itemset = calc_shrink_difference(item)\n",
    "\t\t\t\t\tfor cand in candidates:\n",
    "\t\t\t\t\t\tshrink_difference_cand = calc_shrink_difference(cand)\n",
    "\t\t\t\t\t\tprint(f\"  Evaluating candidate: {cand}\")\n",
    "\t\t\t\t\t\tprint(f\"    Shrink difference itemset: {shink_difference_itemset}, Shrink difference candidate: {shrink_difference_cand}\")\n",
    "\t\t\t\t\t\tif shrink_difference_cand == shink_difference_itemset - 1:\n",
    "\t\t\t\t\t\t\tw_k.append(cand)\n",
    "\t\t\t\t\t\t\tprint(f\"    --> {cand} added to w_k\")\n",
    "\t\t\t\t\t\telse:\n",
    "\t\t\t\t\t\t\tprint(f\"    --> {cand} NOT added to w_k\")\n",
    "\t\t\t\t\t\n",
    "\t\t# valuta i candidati\n",
    "\t\tprint(\"Evaluating candidates...\")\n",
    "\t\ts_w = []\n",
    "\t\tprint(\"Itemsets to evaluate:\", w_k)\n",
    "\t\tfor itemset in w_k:\n",
    "\t\t\tsupport = calc_support(df, itemset, weight_col)\n",
    "\t\t\t# print(f\"Itemset: {itemset}, Support: {support}\")\n",
    "\t\t\tif support >= epsilon:\n",
    "\t\t\t\ts_w.append(itemset)\n",
    "\t\t\t\trelations.append((itemset, support))\n",
    "\t\t\n",
    "\t\tk += 1\n",
    "\t\n",
    "\treturn relations\n",
    "\n",
    "results = a_priori_quant_itemsets(df=df, epsilon=epsilon, weight_col='weight')\n",
    "print(\"\\n--- Frequent itemsets found: ---\\n\")\n",
    "for itemset, support in results:\n",
    "\tprint(f\"Itemset: {itemset}, Support: {support}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6e317c02",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "bottom_itemset() missing 1 required positional argument: 'weught_col'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[11], line 42\u001b[0m\n\u001b[0;32m     38\u001b[0m \t\tlp\u001b[38;5;241m.\u001b[39mremove(random_itemset)\n\u001b[0;32m     40\u001b[0m \t\u001b[38;5;28;01mreturn\u001b[39;00m relations\n\u001b[1;32m---> 42\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[43ma_priori_quant_itemsets_randomic\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepsilon\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     43\u001b[0m \u001b[38;5;28mprint\u001b[39m(results)\n",
      "Cell \u001b[1;32mIn[11], line 7\u001b[0m, in \u001b[0;36ma_priori_quant_itemsets_randomic\u001b[1;34m(df, epsilon)\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21ma_priori_quant_itemsets_randomic\u001b[39m(df, epsilon):\n\u001b[0;32m      6\u001b[0m \trelations \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m----> 7\u001b[0m \tb_itemset \u001b[38;5;241m=\u001b[39m \u001b[43mbottom_itemset\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;66;03m# bottom_itemset restituisce un dict: {col: (low, high)}\u001b[39;00m\n\u001b[0;32m      9\u001b[0m \tlp \u001b[38;5;241m=\u001b[39m [{col: bounds} \u001b[38;5;28;01mfor\u001b[39;00m col, bounds \u001b[38;5;129;01min\u001b[39;00m b_itemset\u001b[38;5;241m.\u001b[39mitems()] \u001b[38;5;66;03m# candidati da esplorare\u001b[39;00m\n\u001b[0;32m     10\u001b[0m \tls \u001b[38;5;241m=\u001b[39m []\n",
      "\u001b[1;31mTypeError\u001b[0m: bottom_itemset() missing 1 required positional argument: 'weught_col'"
     ]
    }
   ],
   "source": [
    "#############################\n",
    "# RANDOMIC\n",
    "#############################\n",
    "\n",
    "def a_priori_quant_itemsets_randomic(df, epsilon):\n",
    "\trelations = []\n",
    "\tb_itemset = bottom_itemset(df) # bottom_itemset restituisce un dict: {col: (low, high)}\n",
    "\n",
    "\tlp = [{col: bounds} for col, bounds in b_itemset.items()] # candidati da esplorare\n",
    "\tls = []\n",
    "\tlns = []\n",
    "\t\n",
    "\twhile lp:\n",
    "\t\tprint(f\"\\n--- Numbers of candidates: {len(lp)} ---\\n\")\n",
    "\t\trandom_itemset = random.choice(lp)\n",
    "\t\tprint(f\"Random itemset selected: {random_itemset}\\n\")\n",
    "\t\t# k = 0\n",
    "\t\tfor itemset in random_itemset:\n",
    "\t\t\tprint(f\"Processing itemset: {itemset}\")\n",
    "\t\t\t# print(k)\n",
    "\t\t\tif itemset in ls or itemset in lns:\n",
    "\t\t\t\tbreak\n",
    "\t\t\telse:\n",
    "\t\t\t\tsupport = calc_support(df, random_itemset)\n",
    "\t\t\t\tif support >= epsilon:\n",
    "\t\t\t\t\trelations.append((random_itemset, support))\n",
    "\t\t\t\t\tls.append(random_itemset)\n",
    "\t\t\t\t\t\n",
    "\t\t\t\t\t# Per ogni itemset I frequente, genera tutti i candidati di dimensione successiva (k+1)\n",
    "\t\t\t\t\tfor col in df.columns:\n",
    "\t\t\t\t\t\tif col not in itemset:\n",
    "\t\t\t\t\t\t\tnew_itemset = random_itemset.copy()\n",
    "\t\t\t\t\t\t\tnew_itemset[col] = new_itemset.pop(itemset)\n",
    "\t\t\t\t\t\t\tlp.append(new_itemset)\n",
    "\t\t\t\telse:\n",
    "\t\t\t\t\tlns.append(random_itemset)\n",
    "\t\t\t# k += 1\n",
    "\t\tlp.remove(random_itemset)\n",
    "\t\t\n",
    "\treturn relations\n",
    "\n",
    "results = a_priori_quant_itemsets_randomic(df, epsilon)\n",
    "print(results)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
