{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b8940658",
   "metadata": {},
   "source": [
    "## **Trace test relabelling and Entropy Analysis**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0e3df42",
   "metadata": {},
   "source": [
    "#### **Import log**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "130b8a6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pm4py\n",
    "from pm4py.objects.log.obj import EventLog, Trace, Event\n",
    "from pm4py.algo.conformance.alignments.petri_net import algorithm as alignments\n",
    "import datetime\n",
    "import random\n",
    "from pm4py.objects.log.importer.xes import importer as xes_importer\n",
    "import numpy as np\n",
    "from copy import deepcopy\n",
    "import math\n",
    "import itertools\n",
    "from collections import defaultdict # mi permette di inizializzare un dizionario con valori di default (0 nel mio caso)\n",
    "from pm4py.objects.petri_net import semantics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01fec5a0",
   "metadata": {},
   "source": [
    "#### **Markov Process**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1949a529",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Sample:\n",
    "\tdef __init__(self, prefix, next_transition, trace_id, position):\n",
    "\t\t\"\"\"Represents a sample (x, y) where x is prefix and y is next transition\"\"\"\n",
    "\t\tself.prefix = prefix  # sequence of events before current position\n",
    "\t\tself.next_transition = next_transition  # transition at current position\t\n",
    "\t\tself.trace_id = trace_id  # which trace this sample comes from\n",
    "\t\tself.position = position  # position in the alignment\n",
    "\t\n",
    "class State:\n",
    "\t\"\"\"Represents a state in the Markov process\"\"\"\n",
    "\tdef __init__(self, state_id, marking):\n",
    "\t\tself.state_id = state_id\n",
    "\t\tself.marking = marking\n",
    "\t\tself.samples = []  # List of Sample objects\n",
    "\t\tself.transitions = defaultdict(int)  # transition -> count\n",
    "\t\tself.total_samples = 0 # totale samples di ogni stato, mi serve come denominatore per calcolare le transition probabilities\n",
    "\t\n",
    "\tdef add_sample(self, sample):\n",
    "\t\tself.samples.append(sample)\n",
    "\t\tself.transitions[sample.next_transition] += 1 # ogni volta che arriva in uno stato, ho la next_transition che arriva dal sample (che a sua volta arriva dal log aligned), sommo 1 ogni volta che compare questa next_transition\n",
    "\t\tself.total_samples += 1\n",
    "\t\n",
    "\tdef get_transition_probabilities(self):\n",
    "\t\t\"\"\"Calculate transition probabilities from this state\"\"\"\n",
    "\t\tif self.total_samples == 0:\n",
    "\t\t\treturn {}\n",
    "\t\t\n",
    "\t\tprobabilities = {}\n",
    "\t\tfor transition, count in self.transitions.items():\n",
    "\t\t\tprobabilities[transition] = count / self.total_samples\n",
    "\t\t# print(f\"State {self.state_id} transition probabilities: {probabilities}\")\n",
    "\t\treturn probabilities\n",
    "\t\t\n",
    "\tdef calculate_entropy(self):\n",
    "\t\t\"\"\"Calculate entropy of this state\"\"\"\n",
    "\t\tprobabilities = self.get_transition_probabilities()\n",
    "\t\tif not probabilities:\n",
    "\t\t\treturn 0.0\n",
    "\t\t\n",
    "\t\tentropy = 0.0\n",
    "\t\tfor prob in probabilities.values():\n",
    "\t\t\tif prob > 0:\n",
    "\t\t\t\tentropy -= prob * math.log2(prob)\n",
    "\t\t# print(f\"State {self.state_id} entropy: {entropy}\")\n",
    "\t\treturn entropy\n",
    "\n",
    "\n",
    "class MarkovProcess:\n",
    "\tdef __init__(self, perfect_aligned_log, net, initial_marking, final_marking):\n",
    "\t\tself.perfect_aligned_log = perfect_aligned_log\n",
    "\t\t# print(\"Perfect aligned log inside MarkovProcess:\", self.perfect_aligned_log)\n",
    "\t\tself.net = net\n",
    "\t\tself.initial_state = None\n",
    "\t\tself.initial_marking = initial_marking\n",
    "\t\tself.final_marking = final_marking\n",
    "\t\tself.total_positions = self.calculate_tot_positions() # numero di tracce * cardinalità della traccia\n",
    "\t\tself.state_visit_counts = defaultdict(int) # per ogni stato, quante volte lo stato è stato visitato\n",
    "\t\t\n",
    "\t\tself.states = self.get_states()  # state_id -> State object\n",
    "\t\t# print(\"States: \", self.states)\n",
    "\t\tself.process_entropy = self.calculate_entropy()\n",
    "\t\t# print(\"Process entropy: \", self.process_entropy)\n",
    "\t\t\n",
    "\tdef get_states(self):\n",
    "\t\t# print(\"Building states from aligned log...\")\n",
    "\t\t\n",
    "\t\tstate_counter = 0\n",
    "\t\tmarking_to_state = {}  # marking -> state_id\n",
    "\t\tstates = {}\n",
    "\t\tfor trace_idx, alignment in enumerate(self.perfect_aligned_log):\n",
    "\t\t\tcurrent_marking = self.initial_marking.copy()\n",
    "\t\t\tfor pos, (trace_event, net_transition) in enumerate(alignment):\n",
    "\t\t\t\tif current_marking is None:\n",
    "\t\t\t\t\t# print(f\"Skipping trace {trace_idx}, pos {pos}: marking is None\")\n",
    "\t\t\t\t\tbreak   # oppure continue, a seconda di cosa vuoi fare\n",
    "\t\t\t\t\n",
    "\t\t\t\t# chiave dello stato dal marking\n",
    "\t\t\t\tmarking_key = tuple(sorted((str(p), c) for p, c in current_marking.items())) # creo la chiave per ogni stato\n",
    "\t\t\t\t\n",
    "\t\t\t\t# Se lo stesso marking c'è già in un’altra traccia, non creo un nuovo stato, ma aggiungio il nuovo sample allo stato già esistente.\n",
    "\t\t\t\tif marking_key not in marking_to_state: # durante l'iterazione dentro la prima traccia entro in questo if e creo tutti gli stati\n",
    "\t\t\t\t\tstate_id = f\"S{state_counter}\"\n",
    "\t\t\t\t\tstate = State(state_id, current_marking.copy())\n",
    "\t\t\t\t\tstates[state_id] = state # aggiungo lo stato al dizionario degli stati\n",
    "\t\t\t\t\tmarking_to_state[marking_key] = state_id # salvo la corrispondenza marking -> state_id\n",
    "\t\t\t\t\tstate_counter += 1 # semplicemente conta gli stati totali\n",
    "\t\t\t\telse:\n",
    "\t\t\t\t\tstate_id = marking_to_state[marking_key]\n",
    "\n",
    "\t\t\t\t# crea sample e lo aggiungo al mio stato per capire che la traccia in questione (trace_idx) al passo pos si trova in questo stato\n",
    "\t\t\t\tprefix = []\n",
    "\t\t\t\tfor i in range(pos):\n",
    "\t\t\t\t\tprev_event, prev_trans = alignment[i]\n",
    "\t\t\t\t\tif prev_event and prev_event not in {\">>\", \"ε\"}: # posso toglierla se considero il perfect log\n",
    "\t\t\t\t\t\tprefix.append(prev_event)\n",
    "\t\t\t\t\t# else:\n",
    "\t\t\t\t\t# \tprint(\"SKIPPPP\")\n",
    "\n",
    "\t\t\t\tif net_transition and net_transition != \">>\": # posso toglierla se considero il perfect log\n",
    "\t\t\t\t\tsample = Sample(prefix, net_transition, trace_idx, pos)\n",
    "\t\t\t\t\tstates[state_id].add_sample(sample)\n",
    "\t\t\t\t\tself.state_visit_counts[state_id] += 1\n",
    "\t\t\t\t\t# self.total_positions += 1 \n",
    "\n",
    "\t\t\t\t\t# aggiorna marking\n",
    "\t\t\t\t\ttransition_obj = next((t for t in self.net.transitions if t.label == net_transition), None)\n",
    "\t\t\t\t\tif transition_obj:\n",
    "\t\t\t\t\t\ttry:\n",
    "\t\t\t\t\t\t\tcurrent_marking = semantics.execute(transition_obj, self.net, current_marking)\n",
    "\t\t\t\t\t\texcept Exception:\n",
    "\t\t\t\t\t\t\tcurrent_marking = None\n",
    "\t\t\t\t# else:\n",
    "\t\t\t\t# \tprint(\"Ciao\")\n",
    "\n",
    "\t\treturn states\n",
    "\t\n",
    "\tdef calculate_tot_positions(self):\n",
    "\t\ttotal_position = sum(len(log) for log in self.perfect_aligned_log)\n",
    "\t\t# print(\"Total positions calculated: \", total_position)\n",
    "\t\treturn total_position\n",
    "\t\n",
    "\tdef calculate_state_probability(self):\n",
    "\t\t# denominator = sum(len(trace) for trace in self.perfect_aligned_log) # positioni totali del log\n",
    "\t\tstate_probabilities = {}\n",
    "\t\tfor state, visit_count in self.state_visit_counts.items():\n",
    "\t\t\tstate_probabilities[state] = visit_count / self.total_positions\n",
    "\t\t\t# print(f\"State {state} has probability {round(state_probabilities[state], 3)}\")\n",
    "\t\treturn state_probabilities\n",
    "\t\n",
    "\tdef calculate_entropy(self):\n",
    "\t\tprocess_entropy = 0.0\n",
    "\t\tstate_probabilities = self.calculate_state_probability()\n",
    "\t\t# print(\"State probabilities:\", state_probabilities)\n",
    "\t\tfor state in self.states.values():\n",
    "\t\t\tstate_entropy = state.calculate_entropy()\n",
    "\t\t\tstate_probability = state_probabilities[state.state_id]\n",
    "\t\t\tprocess_entropy += state_probability * state_entropy\n",
    "\t\treturn process_entropy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90b1569c",
   "metadata": {},
   "source": [
    "#### **Relabelling**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "852c860a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EnrichedLog:\n",
    "\tdef __init__(self, aligned_log, original_log, k,\n",
    "\t\t\t\t name_attr=\"concept:name\", time_attr=\"time:timestamp\",\n",
    "\t\t\t\t include_model_moves=False, binary_as=\"tuple\"):\n",
    "\t\t\"\"\"\n",
    "\t\tinclude_model_moves: se True mantiene anche gli step di model-move con label None\n",
    "\t\tbinary_as: \"tuple\" (default) o \"string\" per la binary_label\n",
    "\t\t\"\"\"\n",
    "\t\tself.aligned_log = aligned_log\n",
    "\t\tself.original_log = original_log\n",
    "\t\tself.k = k\n",
    "\t\tself.name_attr = name_attr\n",
    "\t\tself.time_attr = time_attr\n",
    "\t\tself.include_model_moves = include_model_moves\n",
    "\t\tself.binary_as = binary_as\n",
    "\n",
    "\t\tself.label_to_code = {}\n",
    "\t\tself.code_index = 0\n",
    "\t\tself.all_codes = list(itertools.product([0, 1], repeat=k))\n",
    "\n",
    "\t\tself.enriched_log = self._build_enriched_log()\n",
    "\n",
    "\tdef _get_original_events(self, trace_obj):\n",
    "\t\t# trace_obj può essere Trace (iterable di eventi), oppure dict {'events': [...]}, oppure lista di eventi\n",
    "\t\tif isinstance(trace_obj, dict) and \"events\" in trace_obj:\n",
    "\t\t\treturn trace_obj[\"events\"]\n",
    "\t\t# se è già una lista/Trace la trasformo in lista\n",
    "\t\ttry:\n",
    "\t\t\treturn list(trace_obj)\n",
    "\t\texcept Exception:\n",
    "\t\t\traise ValueError(\"Formato della trace originale non riconosciuto\")\n",
    "\n",
    "\tdef _extract_move_label(self, move):\n",
    "\t\t# move la uso per estrarre label da più parti (self._extract_move_label(model_move), self._extract_move_label(log_move))\n",
    "\t\tif move is None:\n",
    "\t\t\treturn None\n",
    "\t\tif isinstance(move, str):\n",
    "\t\t\treturn move\n",
    "\t\tif isinstance(move, (tuple, list)):\n",
    "\t\t\t# cerchiamo il primo elemento stringa radicato, es. ('Triage',) o ('Triage', 'Triage')\n",
    "\t\t\tfor el in move:\n",
    "\t\t\t\tif isinstance(el, str):\n",
    "\t\t\t\t\treturn el\n",
    "\t\t\t\tif isinstance(el, (tuple, list)) and len(el) > 0 and isinstance(el[0], str):\n",
    "\t\t\t\t\treturn el[0]\n",
    "\t\t\t# fallback\n",
    "\t\t\treturn str(move)\n",
    "\t\treturn str(move)\n",
    "\n",
    "\tdef _get_event_attr(self, event, attr):\n",
    "\t\ttry:\n",
    "\t\t\t# se event è un dict-like o pm4py Event\n",
    "\t\t\treturn event.get(attr) if hasattr(event, \"get\") else event[attr]\n",
    "\t\texcept Exception:\n",
    "\t\t\ttry:\n",
    "\t\t\t\treturn event[attr]\n",
    "\t\t\texcept Exception:\n",
    "\t\t\t\treturn None\n",
    "\n",
    "\tdef _to_timestamp_number(self, ts):\n",
    "\t\tif ts is None:\n",
    "\t\t\treturn None\n",
    "\t\tif isinstance(ts, (int, float)):\n",
    "\t\t\treturn float(ts)\n",
    "\t\tif isinstance(ts, datetime.datetime):\n",
    "\t\t\t# assicurati che sia timezone-aware o locale: timestamp() gestisce UTC\n",
    "\t\t\treturn float(ts.timestamp())\n",
    "\t\t# fallback: prova a convertire\n",
    "\t\ttry:\n",
    "\t\t\treturn float(ts)\n",
    "\t\texcept Exception:\n",
    "\t\t\treturn None\n",
    "\n",
    "\t# core builder\n",
    "\tdef _build_enriched_log(self):\n",
    "\t\tenriched_log = []\n",
    "\n",
    "\t\tfor trace_idx, alignment_info in enumerate(self.aligned_log):\n",
    "\t\t\t# print(alignment_info)\n",
    "\t\t\talignment = alignment_info[\"alignment\"] # self._get_alignment_list(alignment_info)\n",
    "\t\t\torig_trace_obj = self.original_log[trace_idx]\n",
    "\t\t\toriginal_events = self._get_original_events(orig_trace_obj)\n",
    "\n",
    "\t\t\tenriched_trace = []\n",
    "\t\t\tused_indices = set()\n",
    "\t\t\tsearch_start = 0\n",
    "\n",
    "\t\t\tfor step in alignment:\n",
    "\t\t\t\tlog_move, model_move = step\n",
    "\t\t\t\tlog_label = self._extract_move_label(log_move)\n",
    "\t\t\t\t# identifica model-move\n",
    "\t\t\t\tif log_label is None or str(log_label).startswith(\">>\"):\n",
    "\t\t\t\t\tif self.include_model_moves:\n",
    "\t\t\t\t\t\tenriched_trace.append({\n",
    "\t\t\t\t\t\t\t\"original_label\": None,\n",
    "\t\t\t\t\t\t\t\"binary_label\": None,\n",
    "\t\t\t\t\t\t\t\"timestamp\": None,\n",
    "\t\t\t\t\t\t\t\"model_transition\": self._extract_move_label(model_move)\n",
    "\t\t\t\t\t\t})\n",
    "\t\t\t\t\t# non consumiamo eventi del log per model move\n",
    "\t\t\t\t\tcontinue\n",
    "\n",
    "\t\t\t\t# cercho il prossimo evento non usato con lo stesso concept:name\n",
    "\t\t\t\tmatched_idx = None\n",
    "\t\t\t\tfor j in range(search_start, len(original_events)):\n",
    "\t\t\t\t\tif j in used_indices:\n",
    "\t\t\t\t\t\tcontinue\n",
    "\t\t\t\t\tev_name = self._get_event_attr(original_events[j], self.name_attr)\n",
    "\t\t\t\t\tif ev_name == log_label:\n",
    "\t\t\t\t\t\tmatched_idx = j\n",
    "\t\t\t\t\t\tbreak\n",
    "\n",
    "\t\t\t\t# fallback: se non trovato, proviamo a usare il prossimo non usato in ordine\n",
    "\t\t\t\tif matched_idx is None:\n",
    "\t\t\t\t\tfor j in range(search_start, len(original_events)):\n",
    "\t\t\t\t\t\tif j not in used_indices:\n",
    "\t\t\t\t\t\t\tmatched_idx = j\n",
    "\t\t\t\t\t\t\tbreak\n",
    "\n",
    "\t\t\t\tif matched_idx is None:\n",
    "\t\t\t\t\t# non ci sono eventi rimanenti: assegniamo None\n",
    "\t\t\t\t\toriginal_label = log_label\n",
    "\t\t\t\t\tts_num = None\n",
    "\t\t\t\telse:\n",
    "\t\t\t\t\tev = original_events[matched_idx]\n",
    "\t\t\t\t\toriginal_label = self._get_event_attr(ev, self.name_attr)\n",
    "\t\t\t\t\tts = self._get_event_attr(ev, self.time_attr)\n",
    "\t\t\t\t\tts_num = self._to_timestamp_number(ts)\n",
    "\t\t\t\t\tused_indices.add(matched_idx)\n",
    "\t\t\t\t\tsearch_start = matched_idx + 1\n",
    "\n",
    "\t\t\t\t# assegna codice binario coerente per original_label\n",
    "\t\t\t\tcode = None\n",
    "\t\t\t\tif original_label is not None:\n",
    "\t\t\t\t\tif original_label not in self.label_to_code:\n",
    "\t\t\t\t\t\tif self.code_index >= len(self.all_codes):\n",
    "\t\t\t\t\t\t\traise ValueError(f\"Non ci sono abbastanza codici binari (k={self.k}) per etichette uniche trovate; aumenta k\")\n",
    "\t\t\t\t\t\tself.label_to_code[original_label] = self.all_codes[self.code_index]\n",
    "\t\t\t\t\t\tself.code_index += 1\n",
    "\t\t\t\t\tcode = self.label_to_code[original_label]\n",
    "\t\t\t\t\tif self.binary_as == \"string\" and code is not None:\n",
    "\t\t\t\t\t\tcode = \"\".join(map(str, code))\n",
    "\n",
    "\t\t\t\tenriched_trace.append({\n",
    "\t\t\t\t\t\"original_label\": original_label,\n",
    "\t\t\t\t\t\"binary_label\": code,\n",
    "\t\t\t\t\t\"timestamp\": ts_num,\n",
    "\t\t\t\t\t\"model_transition\": self._extract_move_label(model_move)\n",
    "\t\t\t\t})\n",
    "\n",
    "\t\t\tenriched_log.append(enriched_trace)\n",
    "\n",
    "\t\treturn enriched_log\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "620addb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TraceTest():\n",
    "\tdef __init__(self, k=3, min_threshold=1000, max_threshold=10000):\n",
    "\t\tself.psi = [random.choice([-1, 0, 1]) for _ in range(k)]\n",
    "\t\tself.threshold = random.randint(0, max_threshold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c47b4a02",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RelabelledLog:\n",
    "\tdef __init__(self, trace_test_set, log):\n",
    "\t\tself.trace_test_set = trace_test_set  # lista di trace tests\n",
    "\t\tself.log = log  # log originale già arricchito con timestamp e binary_label\n",
    "\t\tself.relabelled_log = self.relabelling_log()\n",
    "\n",
    "\tdef relabelling_log(self):\n",
    "\t\trelabelled_log = []\n",
    "\t\tfor trace in self.log:\n",
    "\t\t\trelabelled_trace = []\n",
    "\t\t\tn = len(trace)\n",
    "\t\t\tfor i, event in enumerate(trace):\n",
    "\t\t\t\ttt_vector_event = []\n",
    "\t\t\t\t# Costruisci il vettore dei trace tests\n",
    "\t\t\t\tfor trace_test in self.trace_test_set:\n",
    "\t\t\t\t\tpsi = trace_test.psi\n",
    "\t\t\t\t\tthreshold = trace_test.threshold\n",
    "\t\t\t\t\tif self.trace_test_holds_position_i(trace, i, psi, threshold):\n",
    "\t\t\t\t\t\ttt_vector_event.append(1)\n",
    "\t\t\t\t\t\t# print(\"Append 1\") # confermato che aggiunge 1\n",
    "\t\t\t\t\telse:\n",
    "\t\t\t\t\t\ttt_vector_event.append(0)\n",
    "\n",
    "\t\t\t\t# Combina evento originale + vettore trace tests\n",
    "\t\t\t\ttt_vector_event_string = \"\".join(map(str, tt_vector_event))\n",
    "\t\t\t\tnew_event = event['original_label'] + tt_vector_event_string\n",
    "\t\t\t\tenriched_event = {\n",
    "\t\t\t\t\t\"original_label\": new_event,\n",
    "\t\t\t\t\t\"binary_label\": event[\"binary_label\"],\n",
    "\t\t\t\t\t\"timestamp\": event[\"timestamp\"],\n",
    "\t\t\t\t\t\"trace_tests\": tt_vector_event\n",
    "\t\t\t\t}\n",
    "\t\t\t\trelabelled_trace.append(enriched_event)\n",
    "\t\t\trelabelled_log.append(relabelled_trace)\n",
    "\n",
    "\t\treturn relabelled_log\n",
    "\n",
    "\tdef trace_test_holds_position_i(self, trace, i, psi, threshold):\n",
    "\t\tt_i = trace[i][\"timestamp\"]\n",
    "\t\t# cerca un evento r <= i che soddisfa psi e sta nel threshold temporale\n",
    "\t\tfor r in range(i, -1, -1):\n",
    "\t\t\tt_r = trace[r][\"timestamp\"]\n",
    "\t\t\tif t_i - t_r <= threshold:\n",
    "\t\t\t\t# print(\"Timestamp sat\") # funziona, viene stampato\n",
    "\t\t\t\tif self.satisfies(trace[r], psi):\n",
    "\t\t\t\t\treturn True\n",
    "\t\treturn False\n",
    "\n",
    "\tdef satisfies(self, event, psi):\n",
    "\t\t# print(\"Psi\",psi)\n",
    "\t\t# print(\"Event\", event)\n",
    "\t\tlabel = event['binary_label']\n",
    "\t\tfor index, value in enumerate(psi):\n",
    "\t\t\tif value != -1:\n",
    "\t\t\t\tif label[index] != value:\n",
    "\t\t\t\t\treturn False\n",
    "\t\treturn True\n",
    "\t\n",
    "\tdef print_trace_test_set(self):\n",
    "\t\tfor trace_test in self.trace_test_set:\n",
    "\t\t\tprint(trace_test.psi, trace_test.threshold)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91cced22",
   "metadata": {},
   "source": [
    "#### **Main function**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73c5efbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "log = xes_importer.apply(\"C:/Users/Simone/Desktop/UNIVERSITA/MAGISTRALE/BIOMEDICAL DECISION SUPPORT SYSTEM/Assignments/2/log-10-percent-noise.xes.gz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73c74520",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_event_log(traces_list):\n",
    "\tlog = EventLog()\n",
    "\tfor trace_data in traces_list:\n",
    "\t\ttrace = Trace()\n",
    "\t\tfor event_data in trace_data[:-1]:\n",
    "\t\t\tevent = Event(event_data)\n",
    "\t\t\ttrace.append(event)\n",
    "\t\tlog.append(trace)\n",
    "\t\n",
    "\treturn log\n",
    "\n",
    "# Build the perfect alignment\n",
    "def build_perfect_alignment(aligned_traces):\n",
    "\tperfect_aligned_log = []\n",
    "\tfor aligned in aligned_traces:\n",
    "\t\taligned_trace = []\n",
    "\t\tfor move_log, move_model in aligned:\n",
    "\t\t\t# keep synchronized moves\n",
    "\t\t\tif move_log not in [None, \">>\"] and move_model not in [None, \">>\"]:\n",
    "\t\t\t\taligned_trace.append((move_log, move_model))\n",
    "\t\t\t\n",
    "\t\t\t# insert dummy for visible model moves (if present)\n",
    "\t\t\telif move_log in [None, \">>\"] and move_model not in [None, \">>\", \"tau\"]:\n",
    "\t\t\t\taligned_trace.append(f\"{move_model}_DUMMY\")\n",
    "\t\t\t\n",
    "\t\t\t# skip all other cases (trace-only moves or tau)\n",
    "\t\t\n",
    "\t\tperfect_aligned_log.append(aligned_trace)\n",
    "\treturn perfect_aligned_log\n",
    "\n",
    "def to_pm4py_log(log):\n",
    "\tpm_log = EventLog()\n",
    "\tfor trace in log:\n",
    "\t\tpm_trace = Trace()\n",
    "\t\tfor event in trace:\n",
    "\t\t\tts = datetime.datetime.fromtimestamp(event['timestamp'])\n",
    "\t\t\tev = Event({\n",
    "\t\t\t\t\"concept:name\": event['original_label'],\n",
    "\t\t\t\t\"time:timestamp\": ts\n",
    "\t\t\t})\n",
    "\t\t\tpm_trace.append(ev)\n",
    "\t\tpm_log.append(pm_trace)\n",
    "\treturn pm_log\n",
    "\n",
    "def filter_trace(aligned_traces):\n",
    "\taligned_log = []\n",
    "\tfor al in aligned_traces:\n",
    "\t\taligned_log.append(al['alignment'])\n",
    "\treturn aligned_log\n",
    "\n",
    "def solve(log, net, initial_marking, final_marking):\n",
    "\tmarkov_process = MarkovProcess(log, net, initial_marking, final_marking)\n",
    "\treturn markov_process.process_entropy\n",
    "\n",
    "def main():\n",
    "\t# Import del log fatto nella cella prima per evitare di caricarlo ogni volta\n",
    "\toriginal_log = log[0:100] # più aumento, più scende l'entropia\n",
    "\toriginal_log = create_event_log(original_log)\n",
    "\n",
    "\t# ======================\n",
    "\t# Enriched log originale\n",
    "\t# ======================\n",
    "\t# Scopro rete e faccio alignment sul training log\n",
    "\tnet, im, fm = pm4py.discover_petri_net_inductive(original_log)\n",
    "\taligned_train = alignments.apply_log(original_log, net, im, fm)\n",
    "\n",
    "\t# ============================\n",
    "\t# Trace test A (singolo) e B (multiplo)\n",
    "\t# ============================\n",
    "\tk = 3\n",
    "\tmin_threshold = 10000\n",
    "\tmax_threshold = 100000\n",
    "\ttrace_test_set_a = [TraceTest(k, min_threshold, max_threshold) for _ in range(1)]\n",
    "\ttrace_test_set_b = [TraceTest(k, min_threshold, max_threshold) for _ in range(10)]\n",
    "\t\n",
    "\t# ======================\n",
    "\t# Original and Relabelled logs\n",
    "\t# ======================\n",
    "\t\n",
    "\toriginal_enriched_log_obj = EnrichedLog(aligned_train, original_log, k)\n",
    "\trelabelled_log_obj_a = RelabelledLog(trace_test_set_a, original_enriched_log_obj.enriched_log)\n",
    "\trelabelled_log_obj_b = RelabelledLog(trace_test_set_b, original_enriched_log_obj.enriched_log)\n",
    "\tprint(\"Enriched original log:\", original_enriched_log_obj.enriched_log[0][0])\n",
    "\tprint(\"Relabelled log A:\", relabelled_log_obj_a.relabelled_log[0][0])\n",
    "\tprint(\"Relabelled log B:\", relabelled_log_obj_b.relabelled_log[0][0])\n",
    "\n",
    "\t# ======================\n",
    "\t# Petri nets dai log\n",
    "\t# ======================\n",
    "\tnet_original_log, im_original, fm_original = pm4py.discover_petri_net_inductive(to_pm4py_log(original_enriched_log_obj.enriched_log))\n",
    "\tnet_relabelled_log_a, im_a, fm_a = pm4py.discover_petri_net_inductive(to_pm4py_log(relabelled_log_obj_a.relabelled_log))\n",
    "\tnet_relabelled_log_b, im_b, fm_b = pm4py.discover_petri_net_inductive(to_pm4py_log(relabelled_log_obj_b.relabelled_log))\n",
    "\n",
    "\t# ======================\n",
    "\t# Alignment\n",
    "\t# ======================\n",
    "\taligned_traces_original_log = alignments.apply_log(to_pm4py_log(original_enriched_log_obj.enriched_log), net_original_log, im_original, fm_original)\n",
    "\taligned_traces_relabelled_log_a = alignments.apply_log(to_pm4py_log(relabelled_log_obj_a.relabelled_log), net_relabelled_log_a, im_a, fm_a)\n",
    "\taligned_traces_relabelled_log_b = alignments.apply_log(to_pm4py_log(relabelled_log_obj_b.relabelled_log), net_relabelled_log_b, im_b, fm_b)\n",
    "\t\n",
    "\t# ======================\n",
    "\t# Filter alignment\n",
    "\t# ======================\n",
    "\taligned_traces_original_log = filter_trace(aligned_traces_original_log)\n",
    "\taligned_traces_relabelled_log_a = filter_trace(aligned_traces_relabelled_log_a)\n",
    "\taligned_traces_relabelled_log_b = filter_trace(aligned_traces_relabelled_log_b)\n",
    "\t\n",
    "\t# ======================\n",
    "\t# Perfect log aligned\n",
    "\t# ======================\n",
    "\t# aligned_traces_original_log = build_perfect_alignment(aligned_traces_original_log)\n",
    "\t# aligned_traces_relabelled_log_a = build_perfect_alignment(aligned_traces_relabelled_log_a)\n",
    "\t# aligned_traces_relabelled_log_b = build_perfect_alignment(aligned_traces_relabelled_log_b)\n",
    "\t\n",
    "\t# ======================\n",
    "\t# Entropie\n",
    "\t# ======================\n",
    "\tentropy_process_original_log = solve(aligned_traces_original_log, net_original_log, im_original, fm_original)\n",
    "\tentropy_process_relabelled_log_a = solve(aligned_traces_relabelled_log_a, net_relabelled_log_a, im_a, fm_a)\n",
    "\tentropy_process_relabelled_log_b = solve(aligned_traces_relabelled_log_b, net_relabelled_log_b, im_b, fm_b)\n",
    "\t\n",
    "\tprint(\"Entropy Original:\", entropy_process_original_log)\n",
    "\tprint(\"Entropy Relabelled A:\", entropy_process_relabelled_log_a)\n",
    "\tprint(\"Entropy Relabelled B:\", entropy_process_relabelled_log_b)\n",
    "\t\n",
    "\n",
    "main()\t"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26523c12",
   "metadata": {},
   "source": [
    "## **Conclusioni**\n",
    "\n",
    "#### **Dimensione del log e entropia**\n",
    "- Più grande è il log di partenza, più bassa tende a essere l'entropia del processo scoperto.\n",
    "- Questo perché log più grandi forniscono più esempi di comportamento, riducendo l'incertezza nella Petri Net scoperta.\n",
    "- Con log piccoli, l'algoritmo ha meno esempi e quindi l'entropia è più alta.\n",
    "\n",
    "---\n",
    "\n",
    "#### **TraceTest e relabelling**\n",
    "- Il relabelling dei TraceTest permette di costruire Petri Net più specifiche e dettagliate.\n",
    "- Ogni evento del log viene reso unico o più distinguibile:\n",
    "  - `Triage` → `Triage001`\n",
    "  - `Check` → `Check002`\n",
    "- Questo riduce ambiguità durante la scoperta della rete, migliorando la fedeltà della Petri Net al log originale.\n",
    "- L’entropia dei log relabelled tende a essere più bassa o più stabile rispetto al log originale.\n",
    "\n",
    "---\n",
    "\n",
    "#### **Analisi combinazioni di TraceTest**\n",
    "- Generare più TraceTest esplora più combinazioni di eventi, aumentando la varietà dei codici binari, rendendo ogni trace più unico.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
