{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "74f2706d",
   "metadata": {},
   "source": [
    "## **Rule Filtering and Shapley Value Analysis**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "715ee679",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "import itertools\n",
    "import pandas as pd\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81028678",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_support(df, itemset, weight_col):\n",
    "\t\"\"\"\n",
    "\titemset è un dict: {colonna: (min_val, max_val), ...}\n",
    "\t\"\"\"\n",
    "\ttotal_weight = df[weight_col].sum()  # somma di tutti i pesi\n",
    "\tnum_sum = 0\n",
    "\n",
    "\t# iteriamo sulle righe del dataframe\n",
    "\tfor index, row in df.iterrows():\n",
    "\t\tmatch = True  # assumiamo che la riga soddisfi le condizioni\n",
    "\n",
    "\t\tfor col, (low, high) in itemset.items():\n",
    "\t\t\tvalue = row[col]\n",
    "\n",
    "\t\t\t# controllo se il valore è dentro i bounds\n",
    "\t\t\tif not (low <= value < high):\n",
    "\t\t\t\tmatch = False\n",
    "\t\t\t\tbreak\n",
    "\n",
    "\t\t# se la riga soddisfa tutti i vincoli dell'itemset\n",
    "\t\tif match:\n",
    "\t\t\tnum_sum += row[weight_col]\n",
    "\n",
    "\tsupport = num_sum / total_weight if total_weight > 0 else 0\n",
    "\treturn support\n",
    "\t\n",
    "\n",
    "def closure_Ant(Ant, df, weight_col='weight'):\n",
    "\tbest = {}  # mappa attr -> (ant, support)\n",
    "\tfor ant in Ant:\n",
    "\t\t# ant è un dict con una sola chiave\n",
    "\t\tattr = list(ant.keys())[0]\n",
    "\t\tinterval = ant[attr]\n",
    "\t\t# print(\"Attr: \", attr, \"Interval: \", interval)\n",
    "\t\tsupport = calc_support(df, {attr: interval}, weight_col=weight_col)\n",
    "\t\t\n",
    "\t\tif attr not in best or support > best[attr][1]:\n",
    "\t\t\tbest[attr] = (ant, support)\n",
    "\t\n",
    "\t# restituisce solo i dict con intervallo massimo per ciascun attributo\n",
    "\treturn [ant for ant, _ in best.values()]\n",
    "\t# prendi solo gli ant con supporto massimo per ciascun attributo\n",
    "\t# prima del return: {'A1': (('A1', (0, 3)), 0.8), 'A2': (('A2', (5, 7)), 1.0)}\n",
    "\t# scorre dentro la lista best e siccome c'è un elemento (key, interval), per ogni key, allora prendo solo l'elemento di quella key\n",
    "\n",
    "def compute_Antj(Ant, Cons):\n",
    "\tants_j = {}\n",
    "\tfor cons in Cons:\n",
    "\t\t# estrai la chiave del dict cons (l'attributo j)\n",
    "\t\tattr_cons = list(cons.keys())[0]\n",
    "\t\tant_j = []\n",
    "\t\tfor ant in Ant:\n",
    "\t\t\tattr_ant = list(ant.keys())[0]  # estrai la chiave del dict ant\n",
    "\t\t\tif attr_ant != attr_cons:\n",
    "\t\t\t\tant_j.append(ant)\n",
    "\t\tants_j[attr_cons] = ant_j\n",
    "\treturn ants_j\n",
    "\n",
    "def all_subsets(lst):\n",
    "\t\"\"\"Return all subsets (as lists of dicts) of a given list of dicts.\"\"\"\n",
    "\tsubsets = []\n",
    "\tfor r in range(len(lst)+1):\n",
    "\t\tfor combo in itertools.combinations(lst, r):\n",
    "\t\t\tif combo:  # skip the empty subset\n",
    "\t\t\t\tsubsets.append(list(combo))\n",
    "\treturn subsets\n",
    "\n",
    "def get_consj_for_j_measure(key, Cons):\n",
    "\tfor cons in Cons:\n",
    "\t\tfor cons_key in cons.keys():   # cons ha una sola chiave\n",
    "\t\t\tif cons_key == key:\n",
    "\t\t\t\treturn cons\n",
    "\treturn None\n",
    "\t\t\n",
    "def compute_j_measure(antecedent, consequent, df, weight_col='weight', eps=1e-10): \n",
    "\t'''Measures how much knowing X reduces uncertaintyabout Y'''\n",
    "\t# antecedent and consequent are dicts\n",
    "\t# print(\"Computing J-measure for antecedent:\", antecedent, \"and consequent:\", consequent)\n",
    "\tattr_ant = list(antecedent.keys())[0]\n",
    "\tinterval_ant = antecedent[attr_ant]\n",
    "\t# print(\"Attr:\", attr, \"Interval:\", interval)\n",
    "\tsupport_antecedent = calc_support(df, {attr_ant: interval_ant}, weight_col)\n",
    "\tattr_cons = list(consequent.keys())[0]\n",
    "\tinterval_cons = consequent[attr_cons]\n",
    "\tsupport_consequent = calc_support(df, {attr_cons: interval_cons}, weight_col)\n",
    "\t# print(\"Computing support for both antecedent and consequent:\", {**antecedent, **consequent})\n",
    "\tsupport_both = calc_support(df, {**antecedent, **consequent}, weight_col)\n",
    "\t\n",
    "\tif support_antecedent == 0 or support_consequent == 0:\n",
    "\t\treturn 0.0\n",
    "\t\n",
    "\tconfidence = support_both / (support_antecedent + eps)\n",
    "\tlift = confidence / (support_consequent + eps)\n",
    "\n",
    "\t# Primo termine\n",
    "\tterm1 = 0.0\n",
    "\tif confidence > 0:\n",
    "\t\tterm1 = confidence * np.log2(lift + eps)\n",
    "\n",
    "\t# Secondo termine\n",
    "\tterm2 = 0.0\n",
    "\tif confidence < 1:  # evita log(0)\n",
    "\t\tratio = (1 - confidence) / (1 - support_consequent + eps)\n",
    "\t\tterm2 = (1 - confidence) * np.log2(ratio + eps)\n",
    "\n",
    "\tj_measure = support_antecedent * (term1 + term2)\n",
    "\n",
    "\t# print(\"Support Antecedent:\", support_antecedent, \"Support Consequent:\", support_consequent, \"Support Both:\", support_both, \"Confidence:\", confidence, \"Lift:\", lift, \"J-measure:\", j_measure)\n",
    "\treturn j_measure\n",
    "\n",
    "def compute_shapley_values(ants_j, Cons, df, weight_col='weight', num_samples=100, eps=1e-10):\n",
    "\t# misura quanto ciascun “giocatore” contribuisce al valore totale di una coalizione.\n",
    "\t\"\"\"\n",
    "\tApproximate Shapley values for each antecedent interval in Antj relative to each consequent.\n",
    "\tants_j: dict mapping cons_attr -> list of antecedents (dicts)\n",
    "\tCons: list of consequent dicts\n",
    "\tdf: dataframe\n",
    "\t\"\"\"\n",
    "\tshapley_values = {}\n",
    "\n",
    "\t# get consequent dict for a given attribute\n",
    "\tdef get_consj_for_j(key):\n",
    "\t\tfor cons in Cons:\n",
    "\t\t\tif key in cons:\n",
    "\t\t\t\treturn cons\n",
    "\t\treturn None\n",
    "\n",
    "\tfor cons_attr, ant_list in ants_j.items():\n",
    "\t\t# initialize Shapley values for each antecedent in Antj\n",
    "\t\tphi = {str(ant): 0.0 for ant in ant_list}\n",
    "\t\tif not ant_list:\n",
    "\t\t\tcontinue\n",
    "\n",
    "\t\tcons_dict = get_consj_for_j(cons_attr)\n",
    "\t\tn = len(ant_list)\n",
    "\n",
    "\t\tfor _ in range(num_samples):\n",
    "\t\t\t# sample a random permutation of antecedents\n",
    "\t\t\tperm = np.random.permutation(ant_list)\n",
    "\n",
    "\t\t\tcoalition = []\n",
    "\t\t\tcoalition_support_prev = 0.0\n",
    "\n",
    "\t\t\tfor ant in perm: # capisco se aggiugnere l'ant alla permutazione vale la pena o meno\n",
    "\t\t\t\t# closure of coalition without current ant\n",
    "\t\t\t\tcl_prev = closure_Ant(coalition, df, weight_col)\n",
    "\t\t\t\t# closure of coalition with current ant added\n",
    "\t\t\t\tcl_new = closure_Ant(coalition + [ant], df, weight_col)\n",
    "\n",
    "\t\t\t\t# compute J-measure\n",
    "\t\t\t\tif cl_new:\n",
    "\t\t\t\t\tj_new = compute_j_measure({k: v for d in cl_new for k, v in d.items()},\n",
    "\t\t\t\t\t\t\t\t\t\t\t  cons_dict, df, weight_col, eps)\n",
    "\t\t\t\telse:\n",
    "\t\t\t\t\tj_new = 0.0\n",
    "\t\t\t\tif cl_prev:\n",
    "\t\t\t\t\tj_prev = compute_j_measure({k: v for d in cl_prev for k, v in d.items()},\n",
    "\t\t\t\t\t\t\t\t\t\t\t   cons_dict, df, weight_col, eps)\n",
    "\t\t\t\telse:\n",
    "\t\t\t\t\tj_prev = 0.0\n",
    "\n",
    "\t\t\t\t# marginal contribution\n",
    "\t\t\t\tphi[str(ant)] += j_new - j_prev\n",
    "\n",
    "\t\t\t\t# add current ant to coalition\n",
    "\t\t\t\tcoalition.append(ant)\n",
    "\n",
    "\t\t# average over num_samples\n",
    "\t\tshapley_values[cons_attr] = {k: round(v/num_samples, 3) for k, v in phi.items()}\n",
    "\n",
    "\treturn shapley_values\n",
    "\n",
    "\n",
    "# ----------------\n",
    "\n",
    "\n",
    "# MAIN \n",
    "def main():\n",
    "\tdata = pd.DataFrame({\n",
    "\t\t'A1': [1.2, 2.5, 3.1, 2.9, 1.5],\n",
    "\t\t'A2': [5.0, 5.5, 6.0, 5.2, 5.1],\n",
    "\t\t'weight': [1, 1, 1, 1, 1]\n",
    "\t})\n",
    "\tdf = pd.DataFrame(data)\n",
    "\t\n",
    "\t# keep only rules with p-value < 0.05 and lift > 1.5\n",
    "\t\n",
    "\tfinal_association_rules = [\n",
    "\t\t{'antecedent': {'A1': (0, 3)}, 'consequent': {'A2': (0, 6)}, 'support': 0.8, 'confidence': 1.0, 'lift': 1.25, 'p_value': 0.2},\n",
    "\t\t{'antecedent': {'A2': (0, 6)}, 'consequent': {'A1': (0, 3)}, 'support': 0.8, 'confidence': 1.0, 'lift': 1.25, 'p_value': 0.2},\n",
    "\t\t{'antecedent': {'A1': (0, 2)}, 'consequent': {'A2': (0, 6)}, 'support': 0.4, 'confidence': 1.0, 'lift': 1.25, 'p_value': 0.6},\n",
    "\t\t{'antecedent': {'A1': (0, 4)}, 'consequent': {'A2': (0, 6)}, 'support': 0.8, 'confidence': 0.8, 'lift': 1.0, 'p_value': 1.0},\n",
    "\t\t{'antecedent': {'A2': (0, 6)}, 'consequent': {'A1': (0, 4)}, 'support': 0.8, 'confidence': 1.0, 'lift': 1.0, 'p_value': 1.0}\n",
    "\t]\n",
    "\n",
    "\tp_threshold = 0.5\n",
    "\tlift_threshold = 1.2\n",
    "\tweight_col = 'weight'\n",
    "\teps = 1e-10\n",
    "\tnum_samples = 100\n",
    "\n",
    "\tfinal_rules = [] # filtro rispetto a lift e p-value\n",
    "\tfor rule in final_association_rules:\n",
    "\t\tif rule['p_value'] < p_threshold and rule['lift'] > lift_threshold:\n",
    "\t\t\tfinal_rules.append(rule)\n",
    "\t\t\t\n",
    "\t# create Ant e Cons lists\n",
    "\tAnt = []\n",
    "\tCons = []\n",
    "\tfor rule in final_rules:\n",
    "\t\tAnt.append(rule['antecedent'])\n",
    "\t\tCons.append(rule['consequent'])\n",
    "\tprint(\"Cons: \" + str(Cons))\n",
    "\t# Ant = [\n",
    "\t# {\"A1\", (0,3)},   # support 0.2\n",
    "\t# {(\"A1\", (3,6)},   # support 0.5\n",
    "\t# {(\"A2\", (5,7)},   # support 0.4\n",
    "\t# {(\"A2\", (7,10)},  # support 0.3\n",
    "\t# ]\n",
    "\t# print(Ant)\n",
    "\t\n",
    "\t# create closure of antecedents, keep for each key only the tuple with the max support\n",
    "\t# example of execution\n",
    "\tcl_Ant = closure_Ant(Ant, df, weight_col=weight_col)\n",
    "\n",
    "\t# compute Antj\t\n",
    "\tants_j = compute_Antj(Ant, Cons)\n",
    "\tprint(\"Antjs:\", ants_j)\n",
    "\t\n",
    "\t# compute CPO\n",
    "\t# cpos = compute_cpo(ants_j, Cons, df, weight_col=weight_col, eps=eps)\n",
    "\t# print(\"CPOs:\", cpos)\n",
    "\t\n",
    "\t# compute shapley values\n",
    "\tshapley_values = compute_shapley_values(ants_j, Cons, df=df, num_samples=num_samples, weight_col=weight_col, eps=eps)\n",
    "\tprint(\"Shapley values:\", shapley_values)\n",
    "\t\n",
    "main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
